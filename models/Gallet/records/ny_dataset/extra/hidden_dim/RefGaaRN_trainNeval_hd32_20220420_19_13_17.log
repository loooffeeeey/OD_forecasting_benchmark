> Seed: 66666
> device: cuda:1
> Loading DataSet from data/ny2016_0101to0331/
> Total Hours: 2184, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Training batches: 53, Validation batches: 6
> Initializing the Training Model: GallatExt, Train type = normal
> Model Structure:
GallatExt(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=32, bias=False)
          (att_out_fc_l): Linear(in_features=32, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=32, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=32, bias=False)
          (att_out_fc_l): Linear(in_features=32, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=32, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=32, bias=False)
          (att_out_fc_l): Linear(in_features=32, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=32, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=32, bias=False)
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
    )
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=128, out_features=1, bias=True)
    (Wa): Linear(in_features=128, out_features=128, bias=False)
    (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)
  )
)
> Constructing the Optimizer: ADAM
> Using SmoothL1Loss as the Loss Function.
> Model sent to cuda:1

learning_rate = 0.01, epochs = 200, num_workers = 20
eval_freq = 5, batch_size = 32, optimizer = ADAM
tune = True, use_AR=None, ref_extent = -1.00
num_heads = 3
Demand task ~ 50.00%, OD task ~ 50.00%

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 15.567441, time_cost = 324.9820 sec (0.1936 sec per sample), RMSE-0 = 176.0592, MAPE-0 = 0.8707, MAE-0 = 21.2007
Training Round 2: loss = 3.765495, time_cost = 315.8919 sec (0.1881 sec per sample), RMSE-0 = 25.7626, MAPE-0 = 0.4125, MAE-0 = 5.4521
Training Round 3: loss = 3.655695, time_cost = 312.9952 sec (0.1864 sec per sample), RMSE-0 = 26.6884, MAPE-0 = 0.4176, MAE-0 = 5.6405
Training Round 4: loss = 3.420619, time_cost = 324.6154 sec (0.1933 sec per sample), RMSE-0 = 25.9172, MAPE-0 = 0.4107, MAE-0 = 5.4363
Training Round 5: loss = 3.298294, time_cost = 319.8532 sec (0.1905 sec per sample), RMSE-0 = 25.2010, MAPE-0 = 0.4154, MAE-0 = 5.3778
!!! Validation : loss = 2.677677, RMSE-0 = 23.5289, MAPE-0 = 0.3954, MAE-0 = 5.1619
Training Round 6: loss = 3.134725, time_cost = 325.4815 sec (0.1939 sec per sample), RMSE-0 = 23.0856, MAPE-0 = 0.4067, MAE-0 = 5.0500
Training Round 7: loss = 3.121419, time_cost = 321.2532 sec (0.1913 sec per sample), RMSE-0 = 24.3245, MAPE-0 = 0.4108, MAE-0 = 5.2888
Training Round 8: loss = 3.192730, time_cost = 324.6396 sec (0.1934 sec per sample), RMSE-0 = 24.6023, MAPE-0 = 0.4084, MAE-0 = 5.3258
Training Round 9: loss = 3.106499, time_cost = 309.2597 sec (0.1842 sec per sample), RMSE-0 = 25.2857, MAPE-0 = 0.4128, MAE-0 = 5.3849
Training Round 10: loss = 3.068029, time_cost = 310.8197 sec (0.1851 sec per sample), RMSE-0 = 25.7070, MAPE-0 = 0.4141, MAE-0 = 5.4844
!!! Validation : loss = 2.513912, RMSE-0 = 19.7152, MAPE-0 = 0.4036, MAE-0 = 4.5854
Training Round 11: loss = 2.889233, time_cost = 320.3847 sec (0.1908 sec per sample), RMSE-0 = 22.0612, MAPE-0 = 0.4062, MAE-0 = 4.9162
Training Round 12: loss = 2.965136, time_cost = 314.6707 sec (0.1874 sec per sample), RMSE-0 = 23.0322, MAPE-0 = 0.4077, MAE-0 = 5.1224
Training Round 13: loss = 2.983048, time_cost = 308.1818 sec (0.1836 sec per sample), RMSE-0 = 23.7652, MAPE-0 = 0.4099, MAE-0 = 5.1816
Training Round 14: loss = 2.866674, time_cost = 314.4164 sec (0.1873 sec per sample), RMSE-0 = 23.0528, MAPE-0 = 0.4049, MAE-0 = 5.0887
Training Round 15: loss = 2.873135, time_cost = 329.5977 sec (0.1963 sec per sample), RMSE-0 = 22.7075, MAPE-0 = 0.4069, MAE-0 = 5.1078
!!! Validation : loss = 2.452013, RMSE-0 = 19.7723, MAPE-0 = 0.4022, MAE-0 = 4.5524
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 16: loss = 2.907599, time_cost = 315.4469 sec (0.1879 sec per sample), RMSE-0 = 24.0317, MAPE-0 = 0.4110, MAE-0 = 5.3050
Training Round 17: loss = 2.764984, time_cost = 331.2307 sec (0.1973 sec per sample), RMSE-0 = 22.4904, MAPE-0 = 0.4100, MAE-0 = 5.0940
Training Round 18: loss = 2.892390, time_cost = 336.9697 sec (0.2007 sec per sample), RMSE-0 = 23.4456, MAPE-0 = 0.4096, MAE-0 = 5.2755
Training Round 19: loss = 2.811054, time_cost = 327.1250 sec (0.1948 sec per sample), RMSE-0 = 23.2339, MAPE-0 = 0.4103, MAE-0 = 5.2277
Training Round 20: loss = 2.785008, time_cost = 313.5637 sec (0.1868 sec per sample), RMSE-0 = 22.2568, MAPE-0 = 0.4128, MAE-0 = 5.1471
!!! Validation : loss = 2.577582, RMSE-0 = 22.3590, MAPE-0 = 0.4227, MAE-0 = 5.2320
Training Round 21: loss = 2.893340, time_cost = 309.9382 sec (0.1846 sec per sample), RMSE-0 = 24.3327, MAPE-0 = 0.4193, MAE-0 = 5.4558
Training Round 22: loss = 2.790917, time_cost = 312.9075 sec (0.1864 sec per sample), RMSE-0 = 23.1916, MAPE-0 = 0.4157, MAE-0 = 5.2667
Training Round 23: loss = 2.756001, time_cost = 325.9414 sec (0.1941 sec per sample), RMSE-0 = 24.0053, MAPE-0 = 0.4200, MAE-0 = 5.4219
Training Round 24: loss = 2.794731, time_cost = 316.9971 sec (0.1888 sec per sample), RMSE-0 = 23.5952, MAPE-0 = 0.4201, MAE-0 = 5.4426
Training Round 25: loss = 2.781753, time_cost = 325.0525 sec (0.1936 sec per sample), RMSE-0 = 23.8106, MAPE-0 = 0.4128, MAE-0 = 5.3897
!!! Validation : loss = 2.862451, RMSE-0 = 22.6371, MAPE-0 = 0.4411, MAE-0 = 5.2615
Training Round 26: loss = 2.748441, time_cost = 332.2231 sec (0.1979 sec per sample), RMSE-0 = 24.1982, MAPE-0 = 0.4146, MAE-0 = 5.4451
Training Round 27: loss = 2.687440, time_cost = 332.9468 sec (0.1983 sec per sample), RMSE-0 = 22.1602, MAPE-0 = 0.4130, MAE-0 = 5.1860
Training Round 28: loss = 2.754142, time_cost = 328.9003 sec (0.1959 sec per sample), RMSE-0 = 23.4482, MAPE-0 = 0.4122, MAE-0 = 5.3185
Training Round 29: loss = 2.662587, time_cost = 324.1827 sec (0.1931 sec per sample), RMSE-0 = 22.4315, MAPE-0 = 0.4106, MAE-0 = 5.1881
Training Round 30: loss = 2.690465, time_cost = 317.2278 sec (0.1889 sec per sample), RMSE-0 = 22.9377, MAPE-0 = 0.4079, MAE-0 = 5.2503
!!! Validation : loss = 3.208352, RMSE-0 = 25.0424, MAPE-0 = 0.4385, MAE-0 = 5.4983
Training Round 31: loss = 2.765014, time_cost = 313.0602 sec (0.1865 sec per sample), RMSE-0 = 25.3349, MAPE-0 = 0.4146, MAE-0 = 5.6173
Training Round 32: loss = 2.705842, time_cost = 320.6237 sec (0.1910 sec per sample), RMSE-0 = 23.0512, MAPE-0 = 0.4056, MAE-0 = 5.2443
Training Round 33: loss = 2.727489, time_cost = 327.1421 sec (0.1948 sec per sample), RMSE-0 = 25.1216, MAPE-0 = 0.4122, MAE-0 = 5.5220
Training Round 34: loss = 2.655387, time_cost = 329.8386 sec (0.1964 sec per sample), RMSE-0 = 23.7341, MAPE-0 = 0.4102, MAE-0 = 5.3660
Training Round 35: loss = 2.739552, time_cost = 334.6584 sec (0.1993 sec per sample), RMSE-0 = 23.6512, MAPE-0 = 0.4058, MAE-0 = 5.2689
!!! Validation : loss = 2.420641, RMSE-0 = 21.7725, MAPE-0 = 0.4177, MAE-0 = 4.8548
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 36: loss = 2.690495, time_cost = 313.9052 sec (0.1870 sec per sample), RMSE-0 = 23.8785, MAPE-0 = 0.4085, MAE-0 = 5.3285
Training Round 37: loss = 2.696083, time_cost = 310.8623 sec (0.1851 sec per sample), RMSE-0 = 25.6589, MAPE-0 = 0.4132, MAE-0 = 5.5469
Training Round 38: loss = 2.626174, time_cost = 311.3456 sec (0.1854 sec per sample), RMSE-0 = 23.0019, MAPE-0 = 0.4051, MAE-0 = 5.2158
Training Round 39: loss = 2.656000, time_cost = 313.6757 sec (0.1868 sec per sample), RMSE-0 = 25.3657, MAPE-0 = 0.4137, MAE-0 = 5.5684
Training Round 40: loss = 2.579289, time_cost = 312.7031 sec (0.1862 sec per sample), RMSE-0 = 21.7781, MAPE-0 = 0.4031, MAE-0 = 5.0605
!!! Validation : loss = 2.505620, RMSE-0 = 19.3564, MAPE-0 = 0.4015, MAE-0 = 4.6527
Training Round 41: loss = 2.634152, time_cost = 310.6925 sec (0.1850 sec per sample), RMSE-0 = 21.5052, MAPE-0 = 0.4025, MAE-0 = 4.9894
Training Round 42: loss = 2.681735, time_cost = 310.4087 sec (0.1849 sec per sample), RMSE-0 = 23.9585, MAPE-0 = 0.4078, MAE-0 = 5.3034
Training Round 43: loss = 2.698833, time_cost = 314.2897 sec (0.1872 sec per sample), RMSE-0 = 23.3863, MAPE-0 = 0.4074, MAE-0 = 5.2112
Training Round 44: loss = 2.568769, time_cost = 314.3413 sec (0.1872 sec per sample), RMSE-0 = 21.0504, MAPE-0 = 0.3973, MAE-0 = 4.8883
Training Round 45: loss = 2.594037, time_cost = 315.0432 sec (0.1876 sec per sample), RMSE-0 = 21.2131, MAPE-0 = 0.4006, MAE-0 = 4.9433
!!! Validation : loss = 2.504377, RMSE-0 = 20.9083, MAPE-0 = 0.4069, MAE-0 = 4.7492
Training Round 46: loss = 2.575028, time_cost = 311.2987 sec (0.1854 sec per sample), RMSE-0 = 21.6587, MAPE-0 = 0.4040, MAE-0 = 5.0290
Training Round 47: loss = 2.560742, time_cost = 315.2126 sec (0.1877 sec per sample), RMSE-0 = 21.9364, MAPE-0 = 0.4021, MAE-0 = 5.0491
Training Round 48: loss = 2.539674, time_cost = 309.3997 sec (0.1843 sec per sample), RMSE-0 = 21.5556, MAPE-0 = 0.4009, MAE-0 = 5.0053
Training Round 49: loss = 2.565766, time_cost = 310.2066 sec (0.1848 sec per sample), RMSE-0 = 22.3214, MAPE-0 = 0.4011, MAE-0 = 5.0923
Training Round 50: loss = 2.551150, time_cost = 310.3106 sec (0.1848 sec per sample), RMSE-0 = 21.7807, MAPE-0 = 0.4004, MAE-0 = 5.0623
!!! Validation : loss = 2.407750, RMSE-0 = 20.8214, MAPE-0 = 0.4123, MAE-0 = 4.8276
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 51: loss = 2.620683, time_cost = 309.9364 sec (0.1846 sec per sample), RMSE-0 = 22.5268, MAPE-0 = 0.4068, MAE-0 = 5.2007
Training Round 52: loss = 2.551899, time_cost = 308.8307 sec (0.1839 sec per sample), RMSE-0 = 21.8721, MAPE-0 = 0.4078, MAE-0 = 5.0996
Training Round 53: loss = 2.582027, time_cost = 312.4048 sec (0.1861 sec per sample), RMSE-0 = 21.7541, MAPE-0 = 0.4041, MAE-0 = 5.0815
Training Round 54: loss = 2.509575, time_cost = 311.7267 sec (0.1857 sec per sample), RMSE-0 = 21.5876, MAPE-0 = 0.4023, MAE-0 = 5.0415
Training Round 55: loss = 2.637109, time_cost = 311.7213 sec (0.1857 sec per sample), RMSE-0 = 22.3980, MAPE-0 = 0.4047, MAE-0 = 5.1459
!!! Validation : loss = 2.499385, RMSE-0 = 22.1924, MAPE-0 = 0.4286, MAE-0 = 5.1991
Training Round 56: loss = 2.545447, time_cost = 308.7425 sec (0.1839 sec per sample), RMSE-0 = 21.5174, MAPE-0 = 0.4056, MAE-0 = 5.0485
Training Round 57: loss = 2.552291, time_cost = 314.2143 sec (0.1871 sec per sample), RMSE-0 = 21.4813, MAPE-0 = 0.4006, MAE-0 = 5.0109
Training Round 58: loss = 2.471729, time_cost = 313.6371 sec (0.1868 sec per sample), RMSE-0 = 21.7133, MAPE-0 = 0.3995, MAE-0 = 5.0280
Training Round 59: loss = 2.525767, time_cost = 309.9491 sec (0.1846 sec per sample), RMSE-0 = 21.9440, MAPE-0 = 0.4017, MAE-0 = 5.0490
Training Round 60: loss = 2.496305, time_cost = 311.6474 sec (0.1856 sec per sample), RMSE-0 = 21.7310, MAPE-0 = 0.4012, MAE-0 = 5.0435
!!! Validation : loss = 2.314559, RMSE-0 = 21.5282, MAPE-0 = 0.4166, MAE-0 = 4.9768
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 61: loss = 2.538275, time_cost = 315.2229 sec (0.1877 sec per sample), RMSE-0 = 22.1407, MAPE-0 = 0.4032, MAE-0 = 5.0973
Training Round 62: loss = 2.527173, time_cost = 309.6057 sec (0.1844 sec per sample), RMSE-0 = 21.9955, MAPE-0 = 0.4094, MAE-0 = 5.1422
Training Round 63: loss = 2.517500, time_cost = 311.7402 sec (0.1857 sec per sample), RMSE-0 = 22.5727, MAPE-0 = 0.4018, MAE-0 = 5.1299
Training Round 64: loss = 2.566396, time_cost = 326.5546 sec (0.1945 sec per sample), RMSE-0 = 22.3959, MAPE-0 = 0.4070, MAE-0 = 5.1687
Training Round 65: loss = 2.483330, time_cost = 308.8842 sec (0.1840 sec per sample), RMSE-0 = 21.7511, MAPE-0 = 0.4046, MAE-0 = 5.0683
!!! Validation : loss = 2.516098, RMSE-0 = 22.5596, MAPE-0 = 0.4298, MAE-0 = 5.3749
Training Round 66: loss = 2.492193, time_cost = 312.5802 sec (0.1862 sec per sample), RMSE-0 = 21.8634, MAPE-0 = 0.4055, MAE-0 = 5.0907
Training Round 67: loss = 2.497895, time_cost = 313.0924 sec (0.1865 sec per sample), RMSE-0 = 22.3919, MAPE-0 = 0.4070, MAE-0 = 5.1245
Training Round 68: loss = 2.529500, time_cost = 314.3438 sec (0.1872 sec per sample), RMSE-0 = 22.8801, MAPE-0 = 0.4062, MAE-0 = 5.2381
Training Round 69: loss = 2.588778, time_cost = 323.0192 sec (0.1924 sec per sample), RMSE-0 = 22.8728, MAPE-0 = 0.4052, MAE-0 = 5.1864
Training Round 70: loss = 2.521039, time_cost = 312.7440 sec (0.1863 sec per sample), RMSE-0 = 23.1552, MAPE-0 = 0.4130, MAE-0 = 5.3155
!!! Validation : loss = 2.588687, RMSE-0 = 25.2390, MAPE-0 = 0.4137, MAE-0 = 5.3158
Training Round 71: loss = 2.502502, time_cost = 318.4839 sec (0.1897 sec per sample), RMSE-0 = 23.2729, MAPE-0 = 0.4170, MAE-0 = 5.3524
Training Round 72: loss = 2.518925, time_cost = 310.3737 sec (0.1849 sec per sample), RMSE-0 = 21.6543, MAPE-0 = 0.4068, MAE-0 = 5.0650
Training Round 73: loss = 2.533794, time_cost = 315.5616 sec (0.1879 sec per sample), RMSE-0 = 21.2995, MAPE-0 = 0.4067, MAE-0 = 5.0422
Training Round 74: loss = 2.440368, time_cost = 329.8954 sec (0.1965 sec per sample), RMSE-0 = 20.6270, MAPE-0 = 0.4026, MAE-0 = 4.9228
Training Round 75: loss = 2.515736, time_cost = 326.2208 sec (0.1943 sec per sample), RMSE-0 = 21.7873, MAPE-0 = 0.4048, MAE-0 = 5.1124
!!! Validation : loss = 2.422617, RMSE-0 = 21.4794, MAPE-0 = 0.4142, MAE-0 = 4.8934
Training Round 76: loss = 2.464678, time_cost = 313.0379 sec (0.1864 sec per sample), RMSE-0 = 22.2452, MAPE-0 = 0.4069, MAE-0 = 5.1647
Training Round 77: loss = 2.419103, time_cost = 314.2336 sec (0.1872 sec per sample), RMSE-0 = 21.9317, MAPE-0 = 0.4075, MAE-0 = 5.1125
Training Round 78: loss = 2.472681, time_cost = 314.5595 sec (0.1873 sec per sample), RMSE-0 = 22.4253, MAPE-0 = 0.4095, MAE-0 = 5.2073
Training Round 79: loss = 2.477027, time_cost = 311.7807 sec (0.1857 sec per sample), RMSE-0 = 21.5880, MAPE-0 = 0.4083, MAE-0 = 5.0588
Training Round 80: loss = 2.453568, time_cost = 330.8365 sec (0.1970 sec per sample), RMSE-0 = 21.8865, MAPE-0 = 0.4021, MAE-0 = 5.0533
!!! Validation : loss = 2.281917, RMSE-0 = 21.1186, MAPE-0 = 0.4119, MAE-0 = 4.8450
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 81: loss = 2.429698, time_cost = 321.1198 sec (0.1913 sec per sample), RMSE-0 = 21.8098, MAPE-0 = 0.4001, MAE-0 = 5.0511
Training Round 82: loss = 2.458935, time_cost = 313.8405 sec (0.1869 sec per sample), RMSE-0 = 21.5671, MAPE-0 = 0.4041, MAE-0 = 5.0200
Training Round 83: loss = 2.454599, time_cost = 314.6645 sec (0.1874 sec per sample), RMSE-0 = 21.9142, MAPE-0 = 0.4046, MAE-0 = 5.0906
Training Round 84: loss = 2.445646, time_cost = 330.1640 sec (0.1966 sec per sample), RMSE-0 = 21.5607, MAPE-0 = 0.4007, MAE-0 = 5.0236
Training Round 85: loss = 2.548441, time_cost = 314.2939 sec (0.1872 sec per sample), RMSE-0 = 23.1019, MAPE-0 = 0.4060, MAE-0 = 5.2311
!!! Validation : loss = 2.438993, RMSE-0 = 29.5085, MAPE-0 = 0.4174, MAE-0 = 5.5540
Training Round 86: loss = 2.467011, time_cost = 310.8545 sec (0.1851 sec per sample), RMSE-0 = 22.4545, MAPE-0 = 0.4010, MAE-0 = 5.0933
Training Round 87: loss = 2.423810, time_cost = 314.3271 sec (0.1872 sec per sample), RMSE-0 = 20.8837, MAPE-0 = 0.3984, MAE-0 = 4.9309
Training Round 88: loss = 2.457797, time_cost = 313.4902 sec (0.1867 sec per sample), RMSE-0 = 21.1033, MAPE-0 = 0.3976, MAE-0 = 4.9434
Training Round 89: loss = 2.449638, time_cost = 316.0587 sec (0.1882 sec per sample), RMSE-0 = 22.1119, MAPE-0 = 0.3992, MAE-0 = 5.0548
Training Round 90: loss = 2.447112, time_cost = 324.2928 sec (0.1931 sec per sample), RMSE-0 = 21.3686, MAPE-0 = 0.3989, MAE-0 = 5.0103
!!! Validation : loss = 2.271662, RMSE-0 = 19.5797, MAPE-0 = 0.4066, MAE-0 = 4.6530
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 91: loss = 2.502460, time_cost = 326.8826 sec (0.1947 sec per sample), RMSE-0 = 22.2796, MAPE-0 = 0.4028, MAE-0 = 5.1329
Training Round 92: loss = 2.439622, time_cost = 329.5135 sec (0.1963 sec per sample), RMSE-0 = 21.4607, MAPE-0 = 0.3970, MAE-0 = 4.9623
Training Round 93: loss = 2.461489, time_cost = 328.9478 sec (0.1959 sec per sample), RMSE-0 = 21.8071, MAPE-0 = 0.3971, MAE-0 = 4.9710
Training Round 94: loss = 2.460962, time_cost = 328.5591 sec (0.1957 sec per sample), RMSE-0 = 21.8397, MAPE-0 = 0.4003, MAE-0 = 5.0323
Training Round 95: loss = 2.415129, time_cost = 311.9672 sec (0.1858 sec per sample), RMSE-0 = 21.1846, MAPE-0 = 0.3960, MAE-0 = 4.9246
!!! Validation : loss = 2.357826, RMSE-0 = 19.9877, MAPE-0 = 0.4179, MAE-0 = 4.7408
Training Round 96: loss = 2.389058, time_cost = 317.5389 sec (0.1891 sec per sample), RMSE-0 = 21.3826, MAPE-0 = 0.3979, MAE-0 = 4.9391
Training Round 97: loss = 2.410749, time_cost = 319.5078 sec (0.1903 sec per sample), RMSE-0 = 21.1096, MAPE-0 = 0.3973, MAE-0 = 4.9204
Training Round 98: loss = 2.496908, time_cost = 319.2850 sec (0.1902 sec per sample), RMSE-0 = 22.0750, MAPE-0 = 0.3965, MAE-0 = 5.0212
Training Round 99: loss = 2.409796, time_cost = 330.1653 sec (0.1966 sec per sample), RMSE-0 = 20.0655, MAPE-0 = 0.3980, MAE-0 = 4.8308
Training Round 100: loss = 2.456666, time_cost = 333.5077 sec (0.1986 sec per sample), RMSE-0 = 19.9683, MAPE-0 = 0.3918, MAE-0 = 4.7243
!!! Validation : loss = 2.553413, RMSE-0 = 19.3274, MAPE-0 = 0.4087, MAE-0 = 4.5674
Training Round 101: loss = 2.432238, time_cost = 318.6318 sec (0.1898 sec per sample), RMSE-0 = 19.9617, MAPE-0 = 0.3927, MAE-0 = 4.7375
Training Round 102: loss = 2.473411, time_cost = 324.5099 sec (0.1933 sec per sample), RMSE-0 = 20.3347, MAPE-0 = 0.3918, MAE-0 = 4.8025
Training Round 103: loss = 2.403374, time_cost = 318.0311 sec (0.1894 sec per sample), RMSE-0 = 19.6724, MAPE-0 = 0.3897, MAE-0 = 4.6696
Training Round 104: loss = 2.374541, time_cost = 321.8386 sec (0.1917 sec per sample), RMSE-0 = 19.5610, MAPE-0 = 0.3883, MAE-0 = 4.6418
Training Round 105: loss = 2.423558, time_cost = 318.3839 sec (0.1896 sec per sample), RMSE-0 = 19.9564, MAPE-0 = 0.3893, MAE-0 = 4.6974
!!! Validation : loss = 2.583453, RMSE-0 = 24.1633, MAPE-0 = 0.4038, MAE-0 = 5.2830
Training Round 106: loss = 2.438543, time_cost = 313.7755 sec (0.1869 sec per sample), RMSE-0 = 20.3864, MAPE-0 = 0.3877, MAE-0 = 4.7077
Training Round 107: loss = 2.433128, time_cost = 315.9975 sec (0.1882 sec per sample), RMSE-0 = 20.2083, MAPE-0 = 0.3897, MAE-0 = 4.6881
Training Round 108: loss = 2.455123, time_cost = 310.4540 sec (0.1849 sec per sample), RMSE-0 = 20.7336, MAPE-0 = 0.3905, MAE-0 = 4.7270
Training Round 109: loss = 2.416913, time_cost = 310.0225 sec (0.1846 sec per sample), RMSE-0 = 20.5951, MAPE-0 = 0.3895, MAE-0 = 4.7217
Training Round 110: loss = 2.386655, time_cost = 320.6355 sec (0.1910 sec per sample), RMSE-0 = 20.5368, MAPE-0 = 0.3903, MAE-0 = 4.7470
!!! Validation : loss = 2.412613, RMSE-0 = 18.3437, MAPE-0 = 0.4009, MAE-0 = 4.3338
Training Round 111: loss = 2.475889, time_cost = 325.8620 sec (0.1941 sec per sample), RMSE-0 = 20.7617, MAPE-0 = 0.3906, MAE-0 = 4.7467
Training Round 112: loss = 2.431238, time_cost = 310.6962 sec (0.1850 sec per sample), RMSE-0 = 20.4539, MAPE-0 = 0.3932, MAE-0 = 4.7430
Training Round 113: loss = 2.416223, time_cost = 320.3230 sec (0.1908 sec per sample), RMSE-0 = 20.5578, MAPE-0 = 0.3909, MAE-0 = 4.7058
Training Round 114: loss = 2.396642, time_cost = 316.7767 sec (0.1887 sec per sample), RMSE-0 = 20.8298, MAPE-0 = 0.3933, MAE-0 = 4.7995
Training Round 115: loss = 2.410415, time_cost = 315.8795 sec (0.1881 sec per sample), RMSE-0 = 20.5030, MAPE-0 = 0.3917, MAE-0 = 4.7176
!!! Validation : loss = 2.392865, RMSE-0 = 21.5146, MAPE-0 = 0.4062, MAE-0 = 4.6909
Training Round 116: loss = 2.427453, time_cost = 326.6290 sec (0.1945 sec per sample), RMSE-0 = 20.2362, MAPE-0 = 0.3934, MAE-0 = 4.7032
Training Round 117: loss = 2.388182, time_cost = 315.7823 sec (0.1881 sec per sample), RMSE-0 = 19.6741, MAPE-0 = 0.3892, MAE-0 = 4.6082
Training Round 118: loss = 2.511788, time_cost = 318.2993 sec (0.1896 sec per sample), RMSE-0 = 20.6763, MAPE-0 = 0.3901, MAE-0 = 4.7413
Training Round 119: loss = 2.523397, time_cost = 322.9841 sec (0.1924 sec per sample), RMSE-0 = 20.6534, MAPE-0 = 0.3916, MAE-0 = 4.7325
Training Round 120: loss = 2.408233, time_cost = 313.0832 sec (0.1865 sec per sample), RMSE-0 = 20.0946, MAPE-0 = 0.3921, MAE-0 = 4.6999
!!! Validation : loss = 2.236158, RMSE-0 = 20.4400, MAPE-0 = 0.3925, MAE-0 = 4.5776
Model: model_save/20220420_19_13_17.pth has been saved since it achieves smaller loss.
Training Round 121: loss = 2.460513, time_cost = 322.7977 sec (0.1923 sec per sample), RMSE-0 = 20.1468, MAPE-0 = 0.3893, MAE-0 = 4.6946
Training Round 122: loss = 2.435866, time_cost = 317.3313 sec (0.1890 sec per sample), RMSE-0 = 20.0151, MAPE-0 = 0.3919, MAE-0 = 4.6596
Training Round 123: loss = 2.393120, time_cost = 309.3907 sec (0.1843 sec per sample), RMSE-0 = 20.0523, MAPE-0 = 0.3886, MAE-0 = 4.6748
Training Round 124: loss = 2.466327, time_cost = 313.4270 sec (0.1867 sec per sample), RMSE-0 = 20.8500, MAPE-0 = 0.3916, MAE-0 = 4.7615
Training Round 125: loss = 2.448251, time_cost = 321.3727 sec (0.1914 sec per sample), RMSE-0 = 20.0611, MAPE-0 = 0.3884, MAE-0 = 4.6579
!!! Validation : loss = 2.284580, RMSE-0 = 18.7397, MAPE-0 = 0.3995, MAE-0 = 4.3322
Training Round 126: loss = 2.470535, time_cost = 315.4113 sec (0.1879 sec per sample), RMSE-0 = 20.2783, MAPE-0 = 0.3908, MAE-0 = 4.7002
Training Round 127: loss = 2.384985, time_cost = 310.4432 sec (0.1849 sec per sample), RMSE-0 = 20.2154, MAPE-0 = 0.3891, MAE-0 = 4.6761
Training Round 128: loss = 2.418529, time_cost = 314.5753 sec (0.1874 sec per sample), RMSE-0 = 20.5752, MAPE-0 = 0.3893, MAE-0 = 4.7344
Training Round 129: loss = 2.434291, time_cost = 321.8452 sec (0.1917 sec per sample), RMSE-0 = 20.3925, MAPE-0 = 0.3902, MAE-0 = 4.7161
Training Round 130: loss = 2.424782, time_cost = 312.4476 sec (0.1861 sec per sample), RMSE-0 = 20.0466, MAPE-0 = 0.3888, MAE-0 = 4.6623
!!! Validation : loss = 2.249350, RMSE-0 = 18.8514, MAPE-0 = 0.3987, MAE-0 = 4.4955
Training Round 131: loss = 2.384171, time_cost = 319.7686 sec (0.1905 sec per sample), RMSE-0 = 19.9423, MAPE-0 = 0.3868, MAE-0 = 4.6414
Training Round 132: loss = 2.387729, time_cost = 318.9036 sec (0.1899 sec per sample), RMSE-0 = 20.5228, MAPE-0 = 0.3894, MAE-0 = 4.7033
Training Round 133: loss = 2.567192, time_cost = 315.1903 sec (0.1877 sec per sample), RMSE-0 = 21.5369, MAPE-0 = 0.3904, MAE-0 = 4.8688
Training Round 134: loss = 2.412882, time_cost = 320.8987 sec (0.1911 sec per sample), RMSE-0 = 19.9519, MAPE-0 = 0.3888, MAE-0 = 4.6350
Training Round 135: loss = 2.408180, time_cost = 331.7401 sec (0.1976 sec per sample), RMSE-0 = 20.3596, MAPE-0 = 0.3882, MAE-0 = 4.6884
!!! Validation : loss = 2.647916, RMSE-0 = 20.0855, MAPE-0 = 0.4075, MAE-0 = 4.5952
Training Round 136: loss = 2.391821, time_cost = 316.5554 sec (0.1885 sec per sample), RMSE-0 = 20.1619, MAPE-0 = 0.3873, MAE-0 = 4.6618
Training Round 137: loss = 2.454770, time_cost = 317.4087 sec (0.1890 sec per sample), RMSE-0 = 20.2594, MAPE-0 = 0.3910, MAE-0 = 4.6904
Training Round 138: loss = 2.384270, time_cost = 328.3804 sec (0.1956 sec per sample), RMSE-0 = 19.9156, MAPE-0 = 0.3870, MAE-0 = 4.6124
Training Round 139: loss = 2.339035, time_cost = 318.1675 sec (0.1895 sec per sample), RMSE-0 = 19.6981, MAPE-0 = 0.3861, MAE-0 = 4.6056
Training Round 140: loss = 2.388201, time_cost = 317.4986 sec (0.1891 sec per sample), RMSE-0 = 19.9796, MAPE-0 = 0.3855, MAE-0 = 4.6188
!!! Validation : loss = 2.286339, RMSE-0 = 17.6140, MAPE-0 = 0.3989, MAE-0 = 4.3071
Training Round 141: loss = 2.337991, time_cost = 312.3013 sec (0.1860 sec per sample), RMSE-0 = 19.3825, MAPE-0 = 0.3856, MAE-0 = 4.5433
Training Round 142: loss = 2.384358, time_cost = 311.1865 sec (0.1853 sec per sample), RMSE-0 = 20.0866, MAPE-0 = 0.3866, MAE-0 = 4.6357
Training Round 143: loss = 2.420999, time_cost = 314.3290 sec (0.1872 sec per sample), RMSE-0 = 20.2948, MAPE-0 = 0.3874, MAE-0 = 4.6394
Training Round 144: loss = 2.435264, time_cost = 315.3945 sec (0.1878 sec per sample), RMSE-0 = 20.1021, MAPE-0 = 0.3878, MAE-0 = 4.6582
Training Round 145: loss = 2.446103, time_cost = 314.6373 sec (0.1874 sec per sample), RMSE-0 = 19.9632, MAPE-0 = 0.3871, MAE-0 = 4.6319
!!! Validation : loss = 2.277918, RMSE-0 = 19.6325, MAPE-0 = 0.3966, MAE-0 = 4.4747
Training Round 146: loss = 2.438477, time_cost = 316.2925 sec (0.1884 sec per sample), RMSE-0 = 20.3730, MAPE-0 = 0.3857, MAE-0 = 4.6917
Training Round 147: loss = 2.411393, time_cost = 313.4560 sec (0.1867 sec per sample), RMSE-0 = 19.5264, MAPE-0 = 0.3888, MAE-0 = 4.6001
Training Round 148: loss = 2.459672, time_cost = 318.4521 sec (0.1897 sec per sample), RMSE-0 = 20.1734, MAPE-0 = 0.3863, MAE-0 = 4.6557
Training Round 149: loss = 2.396805, time_cost = 320.5552 sec (0.1909 sec per sample), RMSE-0 = 19.2866, MAPE-0 = 0.3839, MAE-0 = 4.5488
Training Round 150: loss = 2.291136, time_cost = 330.6665 sec (0.1969 sec per sample), RMSE-0 = 19.1107, MAPE-0 = 0.3838, MAE-0 = 4.4944
!!! Validation : loss = 2.332444, RMSE-0 = 19.4151, MAPE-0 = 0.3980, MAE-0 = 4.4618
Training Round 151: loss = 2.381666, time_cost = 329.1352 sec (0.1960 sec per sample), RMSE-0 = 19.5260, MAPE-0 = 0.3863, MAE-0 = 4.5385
Training Round 152: loss = 2.407043, time_cost = 308.7028 sec (0.1839 sec per sample), RMSE-0 = 19.9990, MAPE-0 = 0.3880, MAE-0 = 4.6270
Training Round 153: loss = 2.370549, time_cost = 320.1472 sec (0.1907 sec per sample), RMSE-0 = 19.7328, MAPE-0 = 0.3865, MAE-0 = 4.6002
Training Round 154: loss = 2.455652, time_cost = 331.5884 sec (0.1975 sec per sample), RMSE-0 = 19.5451, MAPE-0 = 0.3853, MAE-0 = 4.5865
Training Round 155: loss = 2.401431, time_cost = 328.9799 sec (0.1959 sec per sample), RMSE-0 = 19.6431, MAPE-0 = 0.3872, MAE-0 = 4.5910
!!! Validation : loss = 2.272349, RMSE-0 = 17.7481, MAPE-0 = 0.3921, MAE-0 = 4.3413
Training Round 156: loss = 2.386971, time_cost = 313.8897 sec (0.1870 sec per sample), RMSE-0 = 19.7817, MAPE-0 = 0.3856, MAE-0 = 4.6022
Training Round 157: loss = 2.346049, time_cost = 308.8891 sec (0.1840 sec per sample), RMSE-0 = 19.1930, MAPE-0 = 0.3839, MAE-0 = 4.5104
Training Round 158: loss = 2.451023, time_cost = 314.8756 sec (0.1875 sec per sample), RMSE-0 = 19.7527, MAPE-0 = 0.3847, MAE-0 = 4.5964
Training Round 159: loss = 2.357632, time_cost = 319.7784 sec (0.1905 sec per sample), RMSE-0 = 19.4530, MAPE-0 = 0.3824, MAE-0 = 4.5336
Training Round 160: loss = 2.369900, time_cost = 321.0176 sec (0.1912 sec per sample), RMSE-0 = 19.3541, MAPE-0 = 0.3810, MAE-0 = 4.5051
!!! Validation : loss = 2.342325, RMSE-0 = 17.8536, MAPE-0 = 0.3890, MAE-0 = 4.2456
Training Round 161: loss = 2.419822, time_cost = 311.6149 sec (0.1856 sec per sample), RMSE-0 = 19.6686, MAPE-0 = 0.3823, MAE-0 = 4.5516
Training Round 162: loss = 2.398166, time_cost = 312.6724 sec (0.1862 sec per sample), RMSE-0 = 19.3303, MAPE-0 = 0.3827, MAE-0 = 4.5521
Training Round 163: loss = 2.356101, time_cost = 310.0844 sec (0.1847 sec per sample), RMSE-0 = 19.2124, MAPE-0 = 0.3833, MAE-0 = 4.5203
Training Round 164: loss = 2.391916, time_cost = 311.8308 sec (0.1857 sec per sample), RMSE-0 = 19.3934, MAPE-0 = 0.3840, MAE-0 = 4.5564
Training Round 165: loss = 2.424895, time_cost = 312.2510 sec (0.1860 sec per sample), RMSE-0 = 19.5193, MAPE-0 = 0.3838, MAE-0 = 4.5731
!!! Validation : loss = 2.543187, RMSE-0 = 18.8322, MAPE-0 = 0.4073, MAE-0 = 4.4646
Training Round 166: loss = 2.495568, time_cost = 310.5282 sec (0.1849 sec per sample), RMSE-0 = 19.6742, MAPE-0 = 0.3861, MAE-0 = 4.5808
Training Round 167: loss = 2.405717, time_cost = 311.1414 sec (0.1853 sec per sample), RMSE-0 = 19.3531, MAPE-0 = 0.3831, MAE-0 = 4.5434
Training Round 168: loss = 2.424041, time_cost = 309.9618 sec (0.1846 sec per sample), RMSE-0 = 19.0417, MAPE-0 = 0.3838, MAE-0 = 4.5132
Training Round 169: loss = 2.343657, time_cost = 308.8408 sec (0.1839 sec per sample), RMSE-0 = 18.8916, MAPE-0 = 0.3809, MAE-0 = 4.4557
Training Round 170: loss = 2.382933, time_cost = 309.4367 sec (0.1843 sec per sample), RMSE-0 = 19.2683, MAPE-0 = 0.3822, MAE-0 = 4.5387
!!! Validation : loss = 2.482827, RMSE-0 = 18.2466, MAPE-0 = 0.3872, MAE-0 = 4.3855
Training Round 171: loss = 2.387227, time_cost = 311.2441 sec (0.1854 sec per sample), RMSE-0 = 19.1879, MAPE-0 = 0.3819, MAE-0 = 4.5066
Training Round 172: loss = 2.410385, time_cost = 308.8476 sec (0.1839 sec per sample), RMSE-0 = 19.2013, MAPE-0 = 0.3844, MAE-0 = 4.4940
Training Round 173: loss = 2.382986, time_cost = 307.6140 sec (0.1832 sec per sample), RMSE-0 = 19.1712, MAPE-0 = 0.3832, MAE-0 = 4.4900
Training Round 174: loss = 2.411934, time_cost = 308.0030 sec (0.1834 sec per sample), RMSE-0 = 19.4223, MAPE-0 = 0.3822, MAE-0 = 4.5246
Training Round 175: loss = 2.417305, time_cost = 321.0297 sec (0.1912 sec per sample), RMSE-0 = 19.1019, MAPE-0 = 0.3821, MAE-0 = 4.4951
!!! Validation : loss = 2.726896, RMSE-0 = 18.4496, MAPE-0 = 0.3927, MAE-0 = 4.2223
Training Round 176: loss = 2.441653, time_cost = 313.4375 sec (0.1867 sec per sample), RMSE-0 = 20.2987, MAPE-0 = 0.3842, MAE-0 = 4.6604
Training Round 177: loss = 2.385546, time_cost = 313.5540 sec (0.1868 sec per sample), RMSE-0 = 18.9536, MAPE-0 = 0.3836, MAE-0 = 4.5100
Training Round 178: loss = 2.398175, time_cost = 310.9132 sec (0.1852 sec per sample), RMSE-0 = 19.2684, MAPE-0 = 0.3830, MAE-0 = 4.5314
Training Round 179: loss = 2.453041, time_cost = 314.3343 sec (0.1872 sec per sample), RMSE-0 = 19.2844, MAPE-0 = 0.3808, MAE-0 = 4.5371
Training Round 180: loss = 2.405658, time_cost = 318.2953 sec (0.1896 sec per sample), RMSE-0 = 19.1080, MAPE-0 = 0.3806, MAE-0 = 4.5016
!!! Validation : loss = 2.367161, RMSE-0 = 18.0951, MAPE-0 = 0.3916, MAE-0 = 4.3385
Training Round 181: loss = 2.374404, time_cost = 306.2172 sec (0.1824 sec per sample), RMSE-0 = 19.1856, MAPE-0 = 0.3812, MAE-0 = 4.4929
Training Round 182: loss = 2.365467, time_cost = 321.9688 sec (0.1918 sec per sample), RMSE-0 = 19.1955, MAPE-0 = 0.3796, MAE-0 = 4.4945
Training Round 183: loss = 2.345053, time_cost = 314.2837 sec (0.1872 sec per sample), RMSE-0 = 18.9376, MAPE-0 = 0.3797, MAE-0 = 4.4585
Training Round 184: loss = 2.341864, time_cost = 320.1797 sec (0.1907 sec per sample), RMSE-0 = 18.9305, MAPE-0 = 0.3790, MAE-0 = 4.4509
Training Round 185: loss = 2.405311, time_cost = 320.5718 sec (0.1909 sec per sample), RMSE-0 = 19.3410, MAPE-0 = 0.3790, MAE-0 = 4.5131
!!! Validation : loss = 2.284518, RMSE-0 = 17.3523, MAPE-0 = 0.3925, MAE-0 = 4.2404
Training Round 186: loss = 2.466954, time_cost = 320.8124 sec (0.1911 sec per sample), RMSE-0 = 19.9021, MAPE-0 = 0.3806, MAE-0 = 4.6231
Training Round 187: loss = 2.404051, time_cost = 313.8177 sec (0.1869 sec per sample), RMSE-0 = 18.9226, MAPE-0 = 0.3811, MAE-0 = 4.4398
Training Round 188: loss = 2.404237, time_cost = 319.7314 sec (0.1904 sec per sample), RMSE-0 = 19.3744, MAPE-0 = 0.3799, MAE-0 = 4.5131
Training Round 189: loss = 2.382451, time_cost = 322.2462 sec (0.1919 sec per sample), RMSE-0 = 19.0750, MAPE-0 = 0.3802, MAE-0 = 4.4850
Training Round 190: loss = 2.437155, time_cost = 314.4546 sec (0.1873 sec per sample), RMSE-0 = 19.4351, MAPE-0 = 0.3798, MAE-0 = 4.4968
!!! Validation : loss = 2.544509, RMSE-0 = 19.1502, MAPE-0 = 0.3968, MAE-0 = 4.4816
Training Round 191: loss = 2.497467, time_cost = 316.7269 sec (0.1886 sec per sample), RMSE-0 = 19.6249, MAPE-0 = 0.3822, MAE-0 = 4.5712
Training Round 192: loss = 2.424497, time_cost = 314.9676 sec (0.1876 sec per sample), RMSE-0 = 18.8592, MAPE-0 = 0.3799, MAE-0 = 4.4492
Training Round 193: loss = 2.411301, time_cost = 332.4495 sec (0.1980 sec per sample), RMSE-0 = 19.4459, MAPE-0 = 0.3804, MAE-0 = 4.4990
Training Round 194: loss = 2.401982, time_cost = 324.6121 sec (0.1933 sec per sample), RMSE-0 = 18.9698, MAPE-0 = 0.3803, MAE-0 = 4.4653
Training Round 195: loss = 2.371098, time_cost = 312.5104 sec (0.1861 sec per sample), RMSE-0 = 18.6135, MAPE-0 = 0.3789, MAE-0 = 4.4195
!!! Validation : loss = 2.285622, RMSE-0 = 17.2657, MAPE-0 = 0.3891, MAE-0 = 4.1689
Training Round 196: loss = 2.433113, time_cost = 308.1755 sec (0.1835 sec per sample), RMSE-0 = 19.4333, MAPE-0 = 0.3799, MAE-0 = 4.4950
Training Round 197: loss = 2.388739, time_cost = 308.5554 sec (0.1838 sec per sample), RMSE-0 = 19.0556, MAPE-0 = 0.3797, MAE-0 = 4.4416
Training Round 198: loss = 2.399026, time_cost = 311.2035 sec (0.1854 sec per sample), RMSE-0 = 18.8477, MAPE-0 = 0.3792, MAE-0 = 4.4493
Training Round 199: loss = 2.350273, time_cost = 307.7564 sec (0.1833 sec per sample), RMSE-0 = 18.7546, MAPE-0 = 0.3800, MAE-0 = 4.4129
Training Round 200: loss = 2.341249, time_cost = 309.1119 sec (0.1841 sec per sample), RMSE-0 = 19.0760, MAPE-0 = 0.3789, MAE-0 = 4.4216
!!! Validation : loss = 2.353705, RMSE-0 = 18.8292, MAPE-0 = 0.3898, MAE-0 = 4.3176
> Training finished.

> device: cuda:1
> Loading model_save/20220420_19_13_17.pth
> Model Structure:
GallatExt(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=32, bias=False)
          (att_out_fc_l): Linear(in_features=32, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=32, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=32, bias=False)
          (att_out_fc_l): Linear(in_features=32, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=32, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=32, bias=False)
          (att_out_fc_l): Linear(in_features=32, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=32, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=32, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=32, bias=False)
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(128, 128)
      )
    )
    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=128, out_features=1, bias=True)
    (Wa): Linear(in_features=128, out_features=128, bias=False)
    (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)
  )
)
> Model sent to cuda:1
> Loading DataSet from data/ny2016_0101to0331/
> Total Hours: 2184, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Validation batches: 6, Test batches: 11
tune = True, ref_extent = -1.00
num_heads = 3
> Metrics Evaluations for Validation Set:
Demand:
RMSE-0 = 113.4360, RMSE-3 = 148.9753, RMSE-5 = 146.8985
MAPE-0 = 0.6422, MAPE-3 = 0.5603, MAPE-5 = 0.4256
MAE-0 = 27.7342, MAE-3 = 47.4071, MAE-5 = 52.9258
OD:
RMSE-0 = 20.5241, RMSE-3 = 34.2666, RMSE-5 = 39.0691
MAPE-0 = 0.3930, MAPE-3 = 0.3325, MAPE-5 = 0.3054
MAE-0 = 4.5962, MAE-3 = 11.4835, MAE-5 = 14.4175
> Metrics Evaluations for Test Set:
Demand:
RMSE-0 = 92.2651, RMSE-3 = 122.1963, RMSE-5 = 130.6637
MAPE-0 = 0.4037, MAPE-3 = 0.3289, MAPE-5 = 0.2977
MAE-0 = 27.6458, MAE-3 = 47.5531, MAE-5 = 53.9653
OD:
RMSE-0 = 18.7219, RMSE-3 = 32.0849, RMSE-5 = 36.7269
MAPE-0 = 0.3728, MAPE-3 = 0.3266, MAPE-5 = 0.3043
MAE-0 = 4.4734, MAE-3 = 11.2765, MAE-5 = 14.1278
> Evaluation finished.
