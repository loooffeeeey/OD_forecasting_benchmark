> Seed: 66666
> device: cuda:0
> Loading DataSet from data/ny2016_0101to0331/
> Total Hours: 2184, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Training batches: 53, Validation batches: 6
> Initializing the Training Model: GallatExt, Train type = normal
> Model Structure:
GallatExt(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=16, bias=False)
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
    )
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=64, out_features=1, bias=True)
    (Wa): Linear(in_features=64, out_features=64, bias=False)
    (att_out_fc_l): Linear(in_features=64, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=64, out_features=1, bias=False)
  )
)
> Constructing the Optimizer: ADAM
> Using SmoothL1Loss as the Loss Function.
> Model sent to cuda:0

learning_rate = 0.01, epochs = 200, num_workers = 20
eval_freq = 5, batch_size = 32, optimizer = ADAM
tune = True, use_AR=None, ref_extent = -1.00
num_heads = 3
Demand task ~ 10.00%, OD task ~ 90.00%

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 2.315498, time_cost = 310.1012 sec (0.1847 sec per sample), RMSE-0 = 128.2836, MAPE-0 = 0.7435, MAE-0 = 17.5272
Training Round 2: loss = 0.841708, time_cost = 309.5036 sec (0.1843 sec per sample), RMSE-0 = 31.4423, MAPE-0 = 0.4315, MAE-0 = 6.4013
Training Round 3: loss = 0.787046, time_cost = 312.0356 sec (0.1858 sec per sample), RMSE-0 = 28.1760, MAPE-0 = 0.4192, MAE-0 = 5.8515
Training Round 4: loss = 0.715448, time_cost = 315.8219 sec (0.1881 sec per sample), RMSE-0 = 25.0871, MAPE-0 = 0.4129, MAE-0 = 5.2979
Training Round 5: loss = 0.695688, time_cost = 307.4866 sec (0.1831 sec per sample), RMSE-0 = 24.2545, MAPE-0 = 0.4097, MAE-0 = 5.1757
!!! Validation : loss = 0.696225, RMSE-0 = 20.6987, MAPE-0 = 0.3999, MAE-0 = 4.6663
Training Round 6: loss = 0.727143, time_cost = 307.2401 sec (0.1830 sec per sample), RMSE-0 = 25.7317, MAPE-0 = 0.4134, MAE-0 = 5.3962
Training Round 7: loss = 0.718199, time_cost = 315.0751 sec (0.1877 sec per sample), RMSE-0 = 25.9847, MAPE-0 = 0.4119, MAE-0 = 5.4366
Training Round 8: loss = 0.691144, time_cost = 309.6191 sec (0.1844 sec per sample), RMSE-0 = 24.9383, MAPE-0 = 0.4127, MAE-0 = 5.2473
Training Round 9: loss = 0.669725, time_cost = 312.6209 sec (0.1862 sec per sample), RMSE-0 = 24.2941, MAPE-0 = 0.4082, MAE-0 = 5.1538
Training Round 10: loss = 0.668053, time_cost = 314.1438 sec (0.1871 sec per sample), RMSE-0 = 24.8122, MAPE-0 = 0.4086, MAE-0 = 5.2068
!!! Validation : loss = 0.575760, RMSE-0 = 20.8412, MAPE-0 = 0.3937, MAE-0 = 4.7762
Training Round 11: loss = 0.678367, time_cost = 312.6171 sec (0.1862 sec per sample), RMSE-0 = 25.0526, MAPE-0 = 0.4098, MAE-0 = 5.2251
Training Round 12: loss = 0.670356, time_cost = 313.8488 sec (0.1869 sec per sample), RMSE-0 = 25.5587, MAPE-0 = 0.4091, MAE-0 = 5.2956
Training Round 13: loss = 0.661277, time_cost = 309.1980 sec (0.1842 sec per sample), RMSE-0 = 24.8124, MAPE-0 = 0.4103, MAE-0 = 5.2118
Training Round 14: loss = 0.666302, time_cost = 314.9158 sec (0.1876 sec per sample), RMSE-0 = 24.4974, MAPE-0 = 0.4075, MAE-0 = 5.1958
Training Round 15: loss = 0.667002, time_cost = 311.3627 sec (0.1854 sec per sample), RMSE-0 = 25.1938, MAPE-0 = 0.4068, MAE-0 = 5.2528
!!! Validation : loss = 0.601586, RMSE-0 = 21.1538, MAPE-0 = 0.3969, MAE-0 = 4.7248
Model: model_save/20220414_18_46_45.pth has been saved since it achieves smaller loss.
Training Round 16: loss = 0.667569, time_cost = 312.4268 sec (0.1861 sec per sample), RMSE-0 = 24.2369, MAPE-0 = 0.4081, MAE-0 = 5.1731
Training Round 17: loss = 0.663909, time_cost = 308.5300 sec (0.1838 sec per sample), RMSE-0 = 24.0395, MAPE-0 = 0.4056, MAE-0 = 5.0929
Training Round 18: loss = 0.649787, time_cost = 326.9554 sec (0.1947 sec per sample), RMSE-0 = 23.4321, MAPE-0 = 0.4019, MAE-0 = 5.0421
Training Round 19: loss = 0.649039, time_cost = 315.3771 sec (0.1878 sec per sample), RMSE-0 = 23.2575, MAPE-0 = 0.4030, MAE-0 = 5.0057
Training Round 20: loss = 0.648420, time_cost = 307.5821 sec (0.1832 sec per sample), RMSE-0 = 23.5582, MAPE-0 = 0.4061, MAE-0 = 5.0409
!!! Validation : loss = 0.606307, RMSE-0 = 20.2965, MAPE-0 = 0.3935, MAE-0 = 4.5439
Training Round 21: loss = 0.663433, time_cost = 313.3850 sec (0.1866 sec per sample), RMSE-0 = 24.1278, MAPE-0 = 0.4060, MAE-0 = 5.1095
Training Round 22: loss = 0.654280, time_cost = 309.4533 sec (0.1843 sec per sample), RMSE-0 = 23.8271, MAPE-0 = 0.4072, MAE-0 = 5.0849
Training Round 23: loss = 0.644781, time_cost = 307.4125 sec (0.1831 sec per sample), RMSE-0 = 22.7753, MAPE-0 = 0.4039, MAE-0 = 4.9348
Training Round 24: loss = 0.647230, time_cost = 308.5016 sec (0.1837 sec per sample), RMSE-0 = 23.1309, MAPE-0 = 0.4040, MAE-0 = 5.0047
Training Round 25: loss = 0.633466, time_cost = 316.3502 sec (0.1884 sec per sample), RMSE-0 = 22.6088, MAPE-0 = 0.4025, MAE-0 = 4.9054
!!! Validation : loss = 0.534468, RMSE-0 = 18.0679, MAPE-0 = 0.3906, MAE-0 = 4.4213
Model: model_save/20220414_18_46_45.pth has been saved since it achieves smaller loss.
Training Round 26: loss = 0.641509, time_cost = 311.0803 sec (0.1853 sec per sample), RMSE-0 = 22.6431, MAPE-0 = 0.4037, MAE-0 = 4.9007
Training Round 27: loss = 0.657390, time_cost = 307.6722 sec (0.1832 sec per sample), RMSE-0 = 23.7281, MAPE-0 = 0.4053, MAE-0 = 5.0762
Training Round 28: loss = 0.649067, time_cost = 308.7961 sec (0.1839 sec per sample), RMSE-0 = 23.8621, MAPE-0 = 0.4035, MAE-0 = 5.0946
Training Round 29: loss = 0.639350, time_cost = 314.2206 sec (0.1871 sec per sample), RMSE-0 = 22.4177, MAPE-0 = 0.4019, MAE-0 = 4.8770
Training Round 30: loss = 0.648271, time_cost = 318.7757 sec (0.1899 sec per sample), RMSE-0 = 23.9619, MAPE-0 = 0.4031, MAE-0 = 5.1194
!!! Validation : loss = 0.656994, RMSE-0 = 24.1338, MAPE-0 = 0.4150, MAE-0 = 5.1812
Training Round 31: loss = 0.644378, time_cost = 304.2374 sec (0.1812 sec per sample), RMSE-0 = 23.2123, MAPE-0 = 0.4045, MAE-0 = 4.9925
Training Round 32: loss = 0.622510, time_cost = 305.8363 sec (0.1822 sec per sample), RMSE-0 = 22.0246, MAPE-0 = 0.4020, MAE-0 = 4.8345
Training Round 33: loss = 0.636327, time_cost = 313.6549 sec (0.1868 sec per sample), RMSE-0 = 22.5005, MAPE-0 = 0.4008, MAE-0 = 4.9200
Training Round 34: loss = 0.648906, time_cost = 306.2957 sec (0.1824 sec per sample), RMSE-0 = 23.0701, MAPE-0 = 0.4020, MAE-0 = 4.9772
Training Round 35: loss = 0.633061, time_cost = 308.0468 sec (0.1835 sec per sample), RMSE-0 = 23.0130, MAPE-0 = 0.4053, MAE-0 = 4.9250
!!! Validation : loss = 0.535099, RMSE-0 = 18.4784, MAPE-0 = 0.3949, MAE-0 = 4.3156
Training Round 36: loss = 0.619942, time_cost = 314.2198 sec (0.1871 sec per sample), RMSE-0 = 21.6046, MAPE-0 = 0.4008, MAE-0 = 4.7565
Training Round 37: loss = 0.641059, time_cost = 310.5608 sec (0.1850 sec per sample), RMSE-0 = 22.4677, MAPE-0 = 0.4018, MAE-0 = 4.9025
Training Round 38: loss = 0.631272, time_cost = 309.0201 sec (0.1841 sec per sample), RMSE-0 = 22.6858, MAPE-0 = 0.4018, MAE-0 = 4.9131
Training Round 39: loss = 0.652021, time_cost = 309.0704 sec (0.1841 sec per sample), RMSE-0 = 23.4488, MAPE-0 = 0.4031, MAE-0 = 5.0085
Training Round 40: loss = 0.631826, time_cost = 309.2299 sec (0.1842 sec per sample), RMSE-0 = 22.4159, MAPE-0 = 0.4006, MAE-0 = 4.9083
!!! Validation : loss = 0.535317, RMSE-0 = 19.7637, MAPE-0 = 0.3933, MAE-0 = 4.5334
Training Round 41: loss = 0.638493, time_cost = 310.4820 sec (0.1849 sec per sample), RMSE-0 = 22.9682, MAPE-0 = 0.4014, MAE-0 = 4.9210
Training Round 42: loss = 0.643199, time_cost = 308.7210 sec (0.1839 sec per sample), RMSE-0 = 22.2988, MAPE-0 = 0.4019, MAE-0 = 4.8606
Training Round 43: loss = 0.627543, time_cost = 313.0723 sec (0.1865 sec per sample), RMSE-0 = 22.4401, MAPE-0 = 0.4003, MAE-0 = 4.8670
Training Round 44: loss = 0.618570, time_cost = 308.8263 sec (0.1839 sec per sample), RMSE-0 = 21.8524, MAPE-0 = 0.4000, MAE-0 = 4.7738
Training Round 45: loss = 0.626430, time_cost = 307.5925 sec (0.1832 sec per sample), RMSE-0 = 21.8591, MAPE-0 = 0.4001, MAE-0 = 4.8078
!!! Validation : loss = 0.530483, RMSE-0 = 17.6296, MAPE-0 = 0.3898, MAE-0 = 4.3429
Model: model_save/20220414_18_46_45.pth has been saved since it achieves smaller loss.
Training Round 46: loss = 0.621469, time_cost = 332.4572 sec (0.1980 sec per sample), RMSE-0 = 21.8782, MAPE-0 = 0.4002, MAE-0 = 4.7912
Training Round 47: loss = 0.620406, time_cost = 324.6837 sec (0.1934 sec per sample), RMSE-0 = 21.8895, MAPE-0 = 0.3984, MAE-0 = 4.8027
Training Round 48: loss = 0.639811, time_cost = 324.0937 sec (0.1930 sec per sample), RMSE-0 = 22.6076, MAPE-0 = 0.4013, MAE-0 = 4.8997
Training Round 49: loss = 0.623398, time_cost = 323.4469 sec (0.1926 sec per sample), RMSE-0 = 21.9605, MAPE-0 = 0.3992, MAE-0 = 4.7969
Training Round 50: loss = 0.623234, time_cost = 316.0766 sec (0.1883 sec per sample), RMSE-0 = 22.3106, MAPE-0 = 0.3974, MAE-0 = 4.8636
!!! Validation : loss = 0.532287, RMSE-0 = 17.5787, MAPE-0 = 0.3939, MAE-0 = 4.3233
Training Round 51: loss = 0.643863, time_cost = 323.9360 sec (0.1929 sec per sample), RMSE-0 = 24.0497, MAPE-0 = 0.4031, MAE-0 = 5.1058
Training Round 52: loss = 0.619805, time_cost = 304.9109 sec (0.1816 sec per sample), RMSE-0 = 22.0608, MAPE-0 = 0.4010, MAE-0 = 4.8669
Training Round 53: loss = 0.622336, time_cost = 315.5485 sec (0.1879 sec per sample), RMSE-0 = 22.1000, MAPE-0 = 0.4006, MAE-0 = 4.8482
Training Round 54: loss = 0.621808, time_cost = 315.9877 sec (0.1882 sec per sample), RMSE-0 = 22.0306, MAPE-0 = 0.4031, MAE-0 = 4.8593
Training Round 55: loss = 0.621346, time_cost = 312.1143 sec (0.1859 sec per sample), RMSE-0 = 22.2209, MAPE-0 = 0.4002, MAE-0 = 4.8252
!!! Validation : loss = 0.554032, RMSE-0 = 22.4486, MAPE-0 = 0.3863, MAE-0 = 4.8171
Training Round 56: loss = 0.626833, time_cost = 320.6783 sec (0.1910 sec per sample), RMSE-0 = 21.9872, MAPE-0 = 0.3995, MAE-0 = 4.8377
Training Round 57: loss = 0.619880, time_cost = 313.0200 sec (0.1864 sec per sample), RMSE-0 = 21.7644, MAPE-0 = 0.4000, MAE-0 = 4.8022
Training Round 58: loss = 0.616145, time_cost = 313.6625 sec (0.1868 sec per sample), RMSE-0 = 21.5115, MAPE-0 = 0.3986, MAE-0 = 4.7840
Training Round 59: loss = 0.620683, time_cost = 315.3984 sec (0.1878 sec per sample), RMSE-0 = 22.0218, MAPE-0 = 0.3969, MAE-0 = 4.8209
Training Round 60: loss = 0.629887, time_cost = 307.3808 sec (0.1831 sec per sample), RMSE-0 = 22.2742, MAPE-0 = 0.4013, MAE-0 = 4.8477
!!! Validation : loss = 0.543888, RMSE-0 = 18.4787, MAPE-0 = 0.3900, MAE-0 = 4.3764
Training Round 61: loss = 0.616232, time_cost = 309.4408 sec (0.1843 sec per sample), RMSE-0 = 22.0238, MAPE-0 = 0.3980, MAE-0 = 4.8270
Training Round 62: loss = 0.612776, time_cost = 315.1489 sec (0.1877 sec per sample), RMSE-0 = 21.9578, MAPE-0 = 0.3987, MAE-0 = 4.7880
Training Round 63: loss = 0.611767, time_cost = 318.6197 sec (0.1898 sec per sample), RMSE-0 = 21.5559, MAPE-0 = 0.3981, MAE-0 = 4.7568
Training Round 64: loss = 0.632266, time_cost = 315.2902 sec (0.1878 sec per sample), RMSE-0 = 21.9059, MAPE-0 = 0.4001, MAE-0 = 4.8082
Training Round 65: loss = 0.622429, time_cost = 316.7704 sec (0.1887 sec per sample), RMSE-0 = 21.7634, MAPE-0 = 0.4001, MAE-0 = 4.7852
!!! Validation : loss = 0.530768, RMSE-0 = 17.7199, MAPE-0 = 0.3862, MAE-0 = 4.3162
Training Round 66: loss = 0.609189, time_cost = 310.3358 sec (0.1848 sec per sample), RMSE-0 = 21.5455, MAPE-0 = 0.3986, MAE-0 = 4.7498
Training Round 67: loss = 0.618581, time_cost = 313.7846 sec (0.1869 sec per sample), RMSE-0 = 21.5773, MAPE-0 = 0.4004, MAE-0 = 4.7614
Training Round 68: loss = 0.624211, time_cost = 324.0993 sec (0.1930 sec per sample), RMSE-0 = 22.4383, MAPE-0 = 0.3993, MAE-0 = 4.8693
Training Round 69: loss = 0.625555, time_cost = 302.7114 sec (0.1803 sec per sample), RMSE-0 = 22.1627, MAPE-0 = 0.4008, MAE-0 = 4.8776
Training Round 70: loss = 0.604295, time_cost = 316.9937 sec (0.1888 sec per sample), RMSE-0 = 21.3458, MAPE-0 = 0.3995, MAE-0 = 4.7297
!!! Validation : loss = 0.568330, RMSE-0 = 18.5079, MAPE-0 = 0.3985, MAE-0 = 4.4842
Training Round 71: loss = 0.631025, time_cost = 311.1159 sec (0.1853 sec per sample), RMSE-0 = 22.5206, MAPE-0 = 0.3976, MAE-0 = 4.8934
Training Round 72: loss = 0.604078, time_cost = 318.3388 sec (0.1896 sec per sample), RMSE-0 = 21.3405, MAPE-0 = 0.3994, MAE-0 = 4.7554
Training Round 73: loss = 0.631978, time_cost = 322.1663 sec (0.1919 sec per sample), RMSE-0 = 22.3707, MAPE-0 = 0.3989, MAE-0 = 4.8730
Training Round 74: loss = 0.624473, time_cost = 318.2532 sec (0.1895 sec per sample), RMSE-0 = 22.1219, MAPE-0 = 0.4001, MAE-0 = 4.8338
Training Round 75: loss = 0.618735, time_cost = 311.1213 sec (0.1853 sec per sample), RMSE-0 = 21.6511, MAPE-0 = 0.3994, MAE-0 = 4.8015
!!! Validation : loss = 0.566331, RMSE-0 = 19.5756, MAPE-0 = 0.3867, MAE-0 = 4.5702
Training Round 76: loss = 0.620680, time_cost = 316.7241 sec (0.1886 sec per sample), RMSE-0 = 21.7356, MAPE-0 = 0.3977, MAE-0 = 4.7732
Training Round 77: loss = 0.629255, time_cost = 318.3733 sec (0.1896 sec per sample), RMSE-0 = 22.1090, MAPE-0 = 0.3998, MAE-0 = 4.8557
Training Round 78: loss = 0.627280, time_cost = 302.9994 sec (0.1805 sec per sample), RMSE-0 = 22.3259, MAPE-0 = 0.3995, MAE-0 = 4.8294
Training Round 79: loss = 0.617129, time_cost = 309.8413 sec (0.1845 sec per sample), RMSE-0 = 21.3758, MAPE-0 = 0.3976, MAE-0 = 4.7463
Training Round 80: loss = 0.623710, time_cost = 311.3164 sec (0.1854 sec per sample), RMSE-0 = 22.0267, MAPE-0 = 0.3987, MAE-0 = 4.8307
!!! Validation : loss = 0.594494, RMSE-0 = 19.6985, MAPE-0 = 0.3991, MAE-0 = 4.5404
Training Round 81: loss = 0.622579, time_cost = 306.7638 sec (0.1827 sec per sample), RMSE-0 = 21.9482, MAPE-0 = 0.4003, MAE-0 = 4.8133
Training Round 82: loss = 0.611987, time_cost = 306.3735 sec (0.1825 sec per sample), RMSE-0 = 21.5318, MAPE-0 = 0.3989, MAE-0 = 4.7605
Training Round 83: loss = 0.609345, time_cost = 317.2802 sec (0.1890 sec per sample), RMSE-0 = 21.3194, MAPE-0 = 0.3972, MAE-0 = 4.7401
Training Round 84: loss = 0.613116, time_cost = 319.9063 sec (0.1905 sec per sample), RMSE-0 = 21.2458, MAPE-0 = 0.3976, MAE-0 = 4.7293
Training Round 85: loss = 0.611132, time_cost = 317.2728 sec (0.1890 sec per sample), RMSE-0 = 21.4040, MAPE-0 = 0.3989, MAE-0 = 4.7488
!!! Validation : loss = 0.523106, RMSE-0 = 18.0691, MAPE-0 = 0.3864, MAE-0 = 4.2462
Model: model_save/20220414_18_46_45.pth has been saved since it achieves smaller loss.
Training Round 86: loss = 0.620427, time_cost = 319.6948 sec (0.1904 sec per sample), RMSE-0 = 21.9459, MAPE-0 = 0.3986, MAE-0 = 4.7821
Training Round 87: loss = 0.614082, time_cost = 325.4789 sec (0.1939 sec per sample), RMSE-0 = 21.2840, MAPE-0 = 0.3982, MAE-0 = 4.7357
Training Round 88: loss = 0.624707, time_cost = 326.7218 sec (0.1946 sec per sample), RMSE-0 = 22.1155, MAPE-0 = 0.3987, MAE-0 = 4.8325
Training Round 89: loss = 0.605650, time_cost = 316.4263 sec (0.1885 sec per sample), RMSE-0 = 21.1445, MAPE-0 = 0.3960, MAE-0 = 4.7155
Training Round 90: loss = 0.616969, time_cost = 322.4816 sec (0.1921 sec per sample), RMSE-0 = 21.4993, MAPE-0 = 0.3967, MAE-0 = 4.7743
!!! Validation : loss = 0.553544, RMSE-0 = 18.9653, MAPE-0 = 0.3920, MAE-0 = 4.4497
Training Round 91: loss = 0.606710, time_cost = 319.3639 sec (0.1902 sec per sample), RMSE-0 = 21.4818, MAPE-0 = 0.3977, MAE-0 = 4.7550
Training Round 92: loss = 0.612426, time_cost = 304.4930 sec (0.1814 sec per sample), RMSE-0 = 21.6503, MAPE-0 = 0.3975, MAE-0 = 4.7607
Training Round 93: loss = 0.616870, time_cost = 312.7914 sec (0.1863 sec per sample), RMSE-0 = 21.8708, MAPE-0 = 0.3973, MAE-0 = 4.7907
Training Round 94: loss = 0.615160, time_cost = 327.3728 sec (0.1950 sec per sample), RMSE-0 = 21.4316, MAPE-0 = 0.3984, MAE-0 = 4.7532
Training Round 95: loss = 0.611127, time_cost = 330.1356 sec (0.1966 sec per sample), RMSE-0 = 21.2137, MAPE-0 = 0.3971, MAE-0 = 4.7224
!!! Validation : loss = 0.567508, RMSE-0 = 18.1389, MAPE-0 = 0.3927, MAE-0 = 4.2983
Training Round 96: loss = 0.604795, time_cost = 322.7917 sec (0.1923 sec per sample), RMSE-0 = 21.1529, MAPE-0 = 0.3968, MAE-0 = 4.7186
Training Round 97: loss = 0.620060, time_cost = 312.5172 sec (0.1861 sec per sample), RMSE-0 = 21.8172, MAPE-0 = 0.3980, MAE-0 = 4.7799
Training Round 98: loss = 0.603998, time_cost = 315.5087 sec (0.1879 sec per sample), RMSE-0 = 21.2200, MAPE-0 = 0.3972, MAE-0 = 4.7088
Training Round 99: loss = 0.620343, time_cost = 309.5531 sec (0.1844 sec per sample), RMSE-0 = 21.6097, MAPE-0 = 0.3978, MAE-0 = 4.7711
Training Round 100: loss = 0.603664, time_cost = 313.6899 sec (0.1868 sec per sample), RMSE-0 = 21.2028, MAPE-0 = 0.3989, MAE-0 = 4.7102
!!! Validation : loss = 0.524004, RMSE-0 = 18.3629, MAPE-0 = 0.3875, MAE-0 = 4.3725
Training Round 101: loss = 0.606146, time_cost = 319.7537 sec (0.1904 sec per sample), RMSE-0 = 21.2579, MAPE-0 = 0.3966, MAE-0 = 4.6986
Training Round 102: loss = 0.602277, time_cost = 320.7437 sec (0.1910 sec per sample), RMSE-0 = 21.1646, MAPE-0 = 0.3976, MAE-0 = 4.7157
Training Round 103: loss = 0.614833, time_cost = 326.7502 sec (0.1946 sec per sample), RMSE-0 = 21.6107, MAPE-0 = 0.3981, MAE-0 = 4.7499
Training Round 104: loss = 0.613961, time_cost = 321.2537 sec (0.1913 sec per sample), RMSE-0 = 21.5373, MAPE-0 = 0.3972, MAE-0 = 4.7361
Training Round 105: loss = 0.609864, time_cost = 320.6817 sec (0.1910 sec per sample), RMSE-0 = 21.3819, MAPE-0 = 0.3968, MAE-0 = 4.7320
!!! Validation : loss = 0.610577, RMSE-0 = 20.6379, MAPE-0 = 0.3894, MAE-0 = 4.6577
Training Round 106: loss = 0.609640, time_cost = 309.5016 sec (0.1843 sec per sample), RMSE-0 = 21.1743, MAPE-0 = 0.3977, MAE-0 = 4.7480
Training Round 107: loss = 0.598304, time_cost = 323.3905 sec (0.1926 sec per sample), RMSE-0 = 20.9384, MAPE-0 = 0.3949, MAE-0 = 4.6842
Training Round 108: loss = 0.610235, time_cost = 311.1350 sec (0.1853 sec per sample), RMSE-0 = 21.1537, MAPE-0 = 0.3962, MAE-0 = 4.7119
Training Round 109: loss = 0.614809, time_cost = 335.5750 sec (0.1999 sec per sample), RMSE-0 = 21.4458, MAPE-0 = 0.3969, MAE-0 = 4.7568
Training Round 110: loss = 0.618033, time_cost = 319.2337 sec (0.1901 sec per sample), RMSE-0 = 21.2898, MAPE-0 = 0.3978, MAE-0 = 4.7442
!!! Validation : loss = 0.589035, RMSE-0 = 19.3671, MAPE-0 = 0.3851, MAE-0 = 4.5184
Training Round 111: loss = 0.617142, time_cost = 317.8334 sec (0.1893 sec per sample), RMSE-0 = 21.5341, MAPE-0 = 0.3988, MAE-0 = 4.7939
Training Round 112: loss = 0.604487, time_cost = 307.7810 sec (0.1833 sec per sample), RMSE-0 = 21.1876, MAPE-0 = 0.3968, MAE-0 = 4.7282
Training Round 113: loss = 0.618187, time_cost = 319.1928 sec (0.1901 sec per sample), RMSE-0 = 21.8538, MAPE-0 = 0.3974, MAE-0 = 4.7906
Training Round 114: loss = 0.604280, time_cost = 301.3392 sec (0.1795 sec per sample), RMSE-0 = 21.0242, MAPE-0 = 0.3971, MAE-0 = 4.6976
Training Round 115: loss = 0.608448, time_cost = 317.1573 sec (0.1889 sec per sample), RMSE-0 = 21.3776, MAPE-0 = 0.3952, MAE-0 = 4.7291
!!! Validation : loss = 0.528519, RMSE-0 = 18.4416, MAPE-0 = 0.3841, MAE-0 = 4.3265
Training Round 116: loss = 0.612310, time_cost = 307.7167 sec (0.1833 sec per sample), RMSE-0 = 21.6394, MAPE-0 = 0.3985, MAE-0 = 4.7411
Training Round 117: loss = 0.619987, time_cost = 318.4641 sec (0.1897 sec per sample), RMSE-0 = 22.0693, MAPE-0 = 0.3971, MAE-0 = 4.8210
Training Round 118: loss = 0.623837, time_cost = 321.2052 sec (0.1913 sec per sample), RMSE-0 = 21.6389, MAPE-0 = 0.3989, MAE-0 = 4.7845
Training Round 119: loss = 0.604321, time_cost = 318.4685 sec (0.1897 sec per sample), RMSE-0 = 21.3665, MAPE-0 = 0.3963, MAE-0 = 4.7215
Training Round 120: loss = 0.603098, time_cost = 316.7311 sec (0.1886 sec per sample), RMSE-0 = 20.9582, MAPE-0 = 0.3964, MAE-0 = 4.6970
!!! Validation : loss = 0.511852, RMSE-0 = 17.4396, MAPE-0 = 0.3832, MAE-0 = 4.2210
Model: model_save/20220414_18_46_45.pth has been saved since it achieves smaller loss.
Training Round 121: loss = 0.608956, time_cost = 315.9512 sec (0.1882 sec per sample), RMSE-0 = 21.0950, MAPE-0 = 0.3976, MAE-0 = 4.7145
Training Round 122: loss = 0.614546, time_cost = 305.1321 sec (0.1817 sec per sample), RMSE-0 = 21.6221, MAPE-0 = 0.3980, MAE-0 = 4.7794
Training Round 123: loss = 0.611910, time_cost = 308.7340 sec (0.1839 sec per sample), RMSE-0 = 21.2651, MAPE-0 = 0.3965, MAE-0 = 4.7275
Training Round 124: loss = 0.609548, time_cost = 316.6627 sec (0.1886 sec per sample), RMSE-0 = 21.0437, MAPE-0 = 0.3965, MAE-0 = 4.7179
Training Round 125: loss = 0.600025, time_cost = 313.8523 sec (0.1869 sec per sample), RMSE-0 = 20.9758, MAPE-0 = 0.3965, MAE-0 = 4.6905
!!! Validation : loss = 0.548051, RMSE-0 = 18.0306, MAPE-0 = 0.3911, MAE-0 = 4.2330
Training Round 126: loss = 0.606878, time_cost = 325.5070 sec (0.1939 sec per sample), RMSE-0 = 21.1507, MAPE-0 = 0.3983, MAE-0 = 4.7303
Training Round 127: loss = 0.607898, time_cost = 326.5799 sec (0.1945 sec per sample), RMSE-0 = 21.8641, MAPE-0 = 0.3975, MAE-0 = 4.7895
Training Round 128: loss = 0.610861, time_cost = 321.4152 sec (0.1914 sec per sample), RMSE-0 = 21.5002, MAPE-0 = 0.3978, MAE-0 = 4.7602
Training Round 129: loss = 0.616194, time_cost = 311.2333 sec (0.1854 sec per sample), RMSE-0 = 21.8969, MAPE-0 = 0.3977, MAE-0 = 4.8081
Training Round 130: loss = 0.612638, time_cost = 313.6489 sec (0.1868 sec per sample), RMSE-0 = 21.7290, MAPE-0 = 0.3995, MAE-0 = 4.8196
!!! Validation : loss = 0.526549, RMSE-0 = 17.7458, MAPE-0 = 0.3883, MAE-0 = 4.2102
Training Round 131: loss = 0.614785, time_cost = 308.7873 sec (0.1839 sec per sample), RMSE-0 = 21.6377, MAPE-0 = 0.3982, MAE-0 = 4.7645
Training Round 132: loss = 0.614529, time_cost = 307.9975 sec (0.1834 sec per sample), RMSE-0 = 21.5302, MAPE-0 = 0.3979, MAE-0 = 4.7701
Training Round 133: loss = 0.611932, time_cost = 309.2555 sec (0.1842 sec per sample), RMSE-0 = 21.8893, MAPE-0 = 0.3982, MAE-0 = 4.7967
Training Round 134: loss = 0.611190, time_cost = 306.1022 sec (0.1823 sec per sample), RMSE-0 = 21.4764, MAPE-0 = 0.3976, MAE-0 = 4.7723
Training Round 135: loss = 0.624488, time_cost = 308.9646 sec (0.1840 sec per sample), RMSE-0 = 22.0438, MAPE-0 = 0.3970, MAE-0 = 4.8265
!!! Validation : loss = 0.544287, RMSE-0 = 18.2169, MAPE-0 = 0.3832, MAE-0 = 4.2980
Training Round 136: loss = 0.607779, time_cost = 308.5015 sec (0.1837 sec per sample), RMSE-0 = 21.1669, MAPE-0 = 0.3977, MAE-0 = 4.7091
Training Round 137: loss = 0.598983, time_cost = 311.0150 sec (0.1852 sec per sample), RMSE-0 = 21.0268, MAPE-0 = 0.3963, MAE-0 = 4.6763
Training Round 138: loss = 0.603379, time_cost = 309.0249 sec (0.1841 sec per sample), RMSE-0 = 21.0337, MAPE-0 = 0.3962, MAE-0 = 4.6865
Training Round 139: loss = 0.613978, time_cost = 310.8086 sec (0.1851 sec per sample), RMSE-0 = 21.2774, MAPE-0 = 0.3963, MAE-0 = 4.7288
Training Round 140: loss = 0.611647, time_cost = 309.1395 sec (0.1841 sec per sample), RMSE-0 = 21.3235, MAPE-0 = 0.3962, MAE-0 = 4.7146
!!! Validation : loss = 0.550740, RMSE-0 = 17.4232, MAPE-0 = 0.3870, MAE-0 = 4.1844
Training Round 141: loss = 0.610711, time_cost = 308.8803 sec (0.1840 sec per sample), RMSE-0 = 21.0309, MAPE-0 = 0.3976, MAE-0 = 4.6719
Training Round 142: loss = 0.619987, time_cost = 305.0265 sec (0.1817 sec per sample), RMSE-0 = 21.9253, MAPE-0 = 0.3957, MAE-0 = 4.8039
Training Round 143: loss = 0.616510, time_cost = 305.0748 sec (0.1817 sec per sample), RMSE-0 = 21.4585, MAPE-0 = 0.3952, MAE-0 = 4.7492
Training Round 144: loss = 0.605225, time_cost = 304.7647 sec (0.1815 sec per sample), RMSE-0 = 21.0022, MAPE-0 = 0.3966, MAE-0 = 4.6900
Training Round 145: loss = 0.601561, time_cost = 306.5638 sec (0.1826 sec per sample), RMSE-0 = 20.9417, MAPE-0 = 0.3958, MAE-0 = 4.6644
!!! Validation : loss = 0.540229, RMSE-0 = 17.7380, MAPE-0 = 0.3878, MAE-0 = 4.2698
Training Round 146: loss = 0.606615, time_cost = 310.7115 sec (0.1851 sec per sample), RMSE-0 = 20.9919, MAPE-0 = 0.3952, MAE-0 = 4.6941
Training Round 147: loss = 0.604233, time_cost = 306.7627 sec (0.1827 sec per sample), RMSE-0 = 21.2170, MAPE-0 = 0.3951, MAE-0 = 4.7020
Training Round 148: loss = 0.607082, time_cost = 303.9472 sec (0.1810 sec per sample), RMSE-0 = 21.1037, MAPE-0 = 0.3956, MAE-0 = 4.6994
Training Round 149: loss = 0.611645, time_cost = 307.1736 sec (0.1830 sec per sample), RMSE-0 = 21.1964, MAPE-0 = 0.3963, MAE-0 = 4.7336
Training Round 150: loss = 0.622440, time_cost = 308.2509 sec (0.1836 sec per sample), RMSE-0 = 21.7612, MAPE-0 = 0.3964, MAE-0 = 4.7955
!!! Validation : loss = 0.530438, RMSE-0 = 18.3833, MAPE-0 = 0.3918, MAE-0 = 4.3283
Training Round 151: loss = 0.605473, time_cost = 309.4594 sec (0.1843 sec per sample), RMSE-0 = 21.3453, MAPE-0 = 0.3965, MAE-0 = 4.7200
Training Round 152: loss = 0.605085, time_cost = 309.0668 sec (0.1841 sec per sample), RMSE-0 = 21.2813, MAPE-0 = 0.3972, MAE-0 = 4.7252
Training Round 153: loss = 0.602223, time_cost = 308.1250 sec (0.1835 sec per sample), RMSE-0 = 21.0158, MAPE-0 = 0.3958, MAE-0 = 4.7094
Training Round 154: loss = 0.610172, time_cost = 308.6944 sec (0.1839 sec per sample), RMSE-0 = 21.3853, MAPE-0 = 0.3966, MAE-0 = 4.7168
Training Round 155: loss = 0.611028, time_cost = 310.6361 sec (0.1850 sec per sample), RMSE-0 = 21.2173, MAPE-0 = 0.3960, MAE-0 = 4.7019
!!! Validation : loss = 0.515285, RMSE-0 = 17.6196, MAPE-0 = 0.3904, MAE-0 = 4.2590
Training Round 156: loss = 0.608476, time_cost = 306.2702 sec (0.1824 sec per sample), RMSE-0 = 21.2258, MAPE-0 = 0.3971, MAE-0 = 4.7225
Training Round 157: loss = 0.607753, time_cost = 304.8803 sec (0.1816 sec per sample), RMSE-0 = 21.2423, MAPE-0 = 0.3970, MAE-0 = 4.7243
Training Round 158: loss = 0.627162, time_cost = 321.3815 sec (0.1914 sec per sample), RMSE-0 = 22.1724, MAPE-0 = 0.3990, MAE-0 = 4.8657
Training Round 159: loss = 0.614723, time_cost = 318.0740 sec (0.1894 sec per sample), RMSE-0 = 21.4506, MAPE-0 = 0.3966, MAE-0 = 4.7810
Training Round 160: loss = 0.608838, time_cost = 315.0054 sec (0.1876 sec per sample), RMSE-0 = 21.1366, MAPE-0 = 0.3960, MAE-0 = 4.7047
!!! Validation : loss = 0.607412, RMSE-0 = 19.9848, MAPE-0 = 0.3954, MAE-0 = 4.6663
Training Round 161: loss = 0.622512, time_cost = 308.1765 sec (0.1835 sec per sample), RMSE-0 = 21.4972, MAPE-0 = 0.3982, MAE-0 = 4.7716
Training Round 162: loss = 0.611240, time_cost = 314.9169 sec (0.1876 sec per sample), RMSE-0 = 20.9546, MAPE-0 = 0.3961, MAE-0 = 4.6867
Training Round 163: loss = 0.616603, time_cost = 320.5815 sec (0.1909 sec per sample), RMSE-0 = 21.5690, MAPE-0 = 0.3981, MAE-0 = 4.7857
Training Round 164: loss = 0.604642, time_cost = 311.9458 sec (0.1858 sec per sample), RMSE-0 = 21.0263, MAPE-0 = 0.3960, MAE-0 = 4.6984
Training Round 165: loss = 0.604515, time_cost = 313.7794 sec (0.1869 sec per sample), RMSE-0 = 21.1316, MAPE-0 = 0.3957, MAE-0 = 4.7185
!!! Validation : loss = 0.525803, RMSE-0 = 17.6796, MAPE-0 = 0.3848, MAE-0 = 4.2590
Training Round 166: loss = 0.604027, time_cost = 307.0102 sec (0.1829 sec per sample), RMSE-0 = 21.0464, MAPE-0 = 0.3953, MAE-0 = 4.6935
Training Round 167: loss = 0.612925, time_cost = 316.8727 sec (0.1887 sec per sample), RMSE-0 = 21.3264, MAPE-0 = 0.3945, MAE-0 = 4.7030
Training Round 168: loss = 0.612180, time_cost = 319.7551 sec (0.1904 sec per sample), RMSE-0 = 21.2024, MAPE-0 = 0.3962, MAE-0 = 4.7300
Training Round 169: loss = 0.615306, time_cost = 319.9832 sec (0.1906 sec per sample), RMSE-0 = 21.4454, MAPE-0 = 0.3960, MAE-0 = 4.7609
Training Round 170: loss = 0.619528, time_cost = 317.1343 sec (0.1889 sec per sample), RMSE-0 = 21.4760, MAPE-0 = 0.3966, MAE-0 = 4.7528
!!! Validation : loss = 0.560276, RMSE-0 = 18.5430, MAPE-0 = 0.3897, MAE-0 = 4.2598
Training Round 171: loss = 0.610677, time_cost = 316.4222 sec (0.1885 sec per sample), RMSE-0 = 21.2815, MAPE-0 = 0.3954, MAE-0 = 4.7201
Training Round 172: loss = 0.614709, time_cost = 321.8583 sec (0.1917 sec per sample), RMSE-0 = 21.1065, MAPE-0 = 0.3958, MAE-0 = 4.7094
Training Round 173: loss = 0.613408, time_cost = 312.9596 sec (0.1864 sec per sample), RMSE-0 = 21.1690, MAPE-0 = 0.3958, MAE-0 = 4.7296
Training Round 174: loss = 0.617489, time_cost = 310.0499 sec (0.1847 sec per sample), RMSE-0 = 21.8592, MAPE-0 = 0.3980, MAE-0 = 4.7631
Training Round 175: loss = 0.608539, time_cost = 315.6421 sec (0.1880 sec per sample), RMSE-0 = 21.5574, MAPE-0 = 0.3957, MAE-0 = 4.7510
!!! Validation : loss = 0.572698, RMSE-0 = 19.6468, MAPE-0 = 0.3968, MAE-0 = 4.5536
Training Round 176: loss = 0.607750, time_cost = 331.7929 sec (0.1976 sec per sample), RMSE-0 = 21.0868, MAPE-0 = 0.3959, MAE-0 = 4.7103
Training Round 177: loss = 0.609299, time_cost = 319.8784 sec (0.1905 sec per sample), RMSE-0 = 21.2698, MAPE-0 = 0.3955, MAE-0 = 4.7300
Training Round 178: loss = 0.604403, time_cost = 311.6190 sec (0.1856 sec per sample), RMSE-0 = 21.1405, MAPE-0 = 0.3966, MAE-0 = 4.7202
Training Round 179: loss = 0.611660, time_cost = 310.2176 sec (0.1848 sec per sample), RMSE-0 = 20.9575, MAPE-0 = 0.3972, MAE-0 = 4.7119
Training Round 180: loss = 0.607030, time_cost = 312.4387 sec (0.1861 sec per sample), RMSE-0 = 21.4900, MAPE-0 = 0.3962, MAE-0 = 4.7041
!!! Validation : loss = 0.557588, RMSE-0 = 17.8849, MAPE-0 = 0.3856, MAE-0 = 4.2589
Training Round 181: loss = 0.601348, time_cost = 316.3832 sec (0.1884 sec per sample), RMSE-0 = 20.9024, MAPE-0 = 0.3985, MAE-0 = 4.6897
Training Round 182: loss = 0.609416, time_cost = 316.9590 sec (0.1888 sec per sample), RMSE-0 = 21.0826, MAPE-0 = 0.3954, MAE-0 = 4.6920
Training Round 183: loss = 0.616662, time_cost = 311.7264 sec (0.1857 sec per sample), RMSE-0 = 21.0611, MAPE-0 = 0.3956, MAE-0 = 4.6752
Training Round 184: loss = 0.605727, time_cost = 319.4317 sec (0.1903 sec per sample), RMSE-0 = 21.0759, MAPE-0 = 0.3946, MAE-0 = 4.6980
Training Round 185: loss = 0.607976, time_cost = 317.2466 sec (0.1889 sec per sample), RMSE-0 = 21.2463, MAPE-0 = 0.3959, MAE-0 = 4.7117
!!! Validation : loss = 0.510723, RMSE-0 = 17.1608, MAPE-0 = 0.3853, MAE-0 = 4.1126
Model: model_save/20220414_18_46_45.pth has been saved since it achieves smaller loss.
Training Round 186: loss = 0.604061, time_cost = 316.8430 sec (0.1887 sec per sample), RMSE-0 = 21.4050, MAPE-0 = 0.3968, MAE-0 = 4.7321
Training Round 187: loss = 0.599115, time_cost = 318.7905 sec (0.1899 sec per sample), RMSE-0 = 20.9287, MAPE-0 = 0.3966, MAE-0 = 4.7007
Training Round 188: loss = 0.609592, time_cost = 317.0192 sec (0.1888 sec per sample), RMSE-0 = 21.0736, MAPE-0 = 0.3952, MAE-0 = 4.6943
Training Round 189: loss = 0.621171, time_cost = 324.8106 sec (0.1935 sec per sample), RMSE-0 = 21.5338, MAPE-0 = 0.3980, MAE-0 = 4.7599
Training Round 190: loss = 0.614429, time_cost = 318.0480 sec (0.1894 sec per sample), RMSE-0 = 21.3172, MAPE-0 = 0.3980, MAE-0 = 4.7087
!!! Validation : loss = 0.541449, RMSE-0 = 17.6447, MAPE-0 = 0.3898, MAE-0 = 4.2135
Training Round 191: loss = 0.604352, time_cost = 316.1248 sec (0.1883 sec per sample), RMSE-0 = 20.8771, MAPE-0 = 0.3961, MAE-0 = 4.6815
Training Round 192: loss = 0.607532, time_cost = 313.2210 sec (0.1866 sec per sample), RMSE-0 = 21.0827, MAPE-0 = 0.3949, MAE-0 = 4.6976
Training Round 193: loss = 0.622141, time_cost = 314.3235 sec (0.1872 sec per sample), RMSE-0 = 22.6322, MAPE-0 = 0.3981, MAE-0 = 4.8988
Training Round 194: loss = 0.602468, time_cost = 306.4624 sec (0.1825 sec per sample), RMSE-0 = 21.3835, MAPE-0 = 0.3976, MAE-0 = 4.7324
Training Round 195: loss = 0.610246, time_cost = 308.4498 sec (0.1837 sec per sample), RMSE-0 = 21.4880, MAPE-0 = 0.3960, MAE-0 = 4.7518
!!! Validation : loss = 0.561162, RMSE-0 = 18.6593, MAPE-0 = 0.3875, MAE-0 = 4.3623
Training Round 196: loss = 0.607224, time_cost = 311.6230 sec (0.1856 sec per sample), RMSE-0 = 21.3436, MAPE-0 = 0.3963, MAE-0 = 4.7290
Training Round 197: loss = 0.612657, time_cost = 310.1249 sec (0.1847 sec per sample), RMSE-0 = 21.2391, MAPE-0 = 0.3949, MAE-0 = 4.6896
Training Round 198: loss = 0.617059, time_cost = 309.8383 sec (0.1845 sec per sample), RMSE-0 = 21.4312, MAPE-0 = 0.3959, MAE-0 = 4.7250
Training Round 199: loss = 0.609525, time_cost = 307.2206 sec (0.1830 sec per sample), RMSE-0 = 21.3808, MAPE-0 = 0.3975, MAE-0 = 4.7455
Training Round 200: loss = 0.616813, time_cost = 302.8539 sec (0.1804 sec per sample), RMSE-0 = 21.8199, MAPE-0 = 0.3969, MAE-0 = 4.7926
!!! Validation : loss = 0.565597, RMSE-0 = 18.4959, MAPE-0 = 0.3902, MAE-0 = 4.3700
> Training finished.

> device: cuda:0
> Loading model_save/20220414_18_46_45.pth
> Model Structure:
GallatExt(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=16, bias=False)
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
    )
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=64, out_features=1, bias=True)
    (Wa): Linear(in_features=64, out_features=64, bias=False)
    (att_out_fc_l): Linear(in_features=64, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=64, out_features=1, bias=False)
  )
)
> Model sent to cuda:0
> Loading DataSet from data/ny2016_0101to0331/
> Total Hours: 2184, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Validation batches: 6, Test batches: 11
tune = True, ref_extent = -1.00
num_heads = 3
> Metrics Evaluations for Validation Set:
Demand:
RMSE-0 = 123.7436, RMSE-3 = 162.9910, RMSE-5 = 162.1203
MAPE-0 = 0.6284, MAPE-3 = 0.5502, MAPE-5 = 0.4104
MAE-0 = 31.6155, MAE-3 = 54.2962, MAE-5 = 60.7751
OD:
RMSE-0 = 17.4503, RMSE-3 = 29.0923, RMSE-5 = 33.1069
MAPE-0 = 0.3857, MAPE-3 = 0.3145, MAPE-5 = 0.2848
MAE-0 = 4.1349, MAE-3 = 10.1411, MAE-5 = 12.6659
> Metrics Evaluations for Test Set:
Demand:
RMSE-0 = 103.1341, RMSE-3 = 136.5969, RMSE-5 = 146.0652
MAPE-0 = 0.4092, MAPE-3 = 0.3356, MAPE-5 = 0.3049
MAE-0 = 30.6079, MAE-3 = 52.7521, MAE-5 = 59.9092
OD:
RMSE-0 = 15.5712, RMSE-3 = 26.6553, RMSE-5 = 30.4954
MAPE-0 = 0.3708, MAPE-3 = 0.3112, MAPE-5 = 0.2856
MAE-0 = 3.9894, MAE-3 = 9.8302, MAE-5 = 12.2376
> Evaluation finished.
