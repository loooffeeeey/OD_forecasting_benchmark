> Seed: 66666
> device: cuda:2
> Loading DataSet from data/ny2016_0101to0331/
> Total Hours: 2184, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Training batches: 53, Validation batches: 6
> Initializing the Training Model: GallatExt, Train type = normal
> Model Structure:
GallatExt(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=16, bias=False)
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
    )
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=64, out_features=1, bias=True)
    (Wa): Linear(in_features=64, out_features=64, bias=False)
    (att_out_fc_l): Linear(in_features=64, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=64, out_features=1, bias=False)
  )
)
> Constructing the Optimizer: ADAM
> Using SmoothL1Loss as the Loss Function.
> Model sent to cuda:2

learning_rate = 0.01, epochs = 200, num_workers = 20
eval_freq = 5, batch_size = 32, optimizer = ADAM
tune = True, use_AR=None, ref_extent = -1.00
num_heads = 1

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 11.431316, time_cost = 282.0169 sec (0.1680 sec per sample), RMSE-0 = 117.0002, MAPE-0 = 0.7202, MAE-0 = 16.5210
Training Round 2: loss = 3.902840, time_cost = 286.8621 sec (0.1709 sec per sample), RMSE-0 = 28.5568, MAPE-0 = 0.4270, MAE-0 = 5.9096
Training Round 3: loss = 3.636031, time_cost = 296.5985 sec (0.1767 sec per sample), RMSE-0 = 26.5516, MAPE-0 = 0.4199, MAE-0 = 5.6208
Training Round 4: loss = 3.381373, time_cost = 290.6717 sec (0.1731 sec per sample), RMSE-0 = 24.5521, MAPE-0 = 0.4152, MAE-0 = 5.2755
Training Round 5: loss = 3.298280, time_cost = 284.1108 sec (0.1692 sec per sample), RMSE-0 = 24.2826, MAPE-0 = 0.4144, MAE-0 = 5.2515
!!! Validation : loss = 2.798097, RMSE-0 = 20.8442, MAPE-0 = 0.4114, MAE-0 = 4.7420
Training Round 6: loss = 3.228221, time_cost = 277.7138 sec (0.1654 sec per sample), RMSE-0 = 23.7019, MAPE-0 = 0.4141, MAE-0 = 5.1174
Training Round 7: loss = 3.234840, time_cost = 285.5353 sec (0.1701 sec per sample), RMSE-0 = 23.9840, MAPE-0 = 0.4116, MAE-0 = 5.1799
Training Round 8: loss = 3.084742, time_cost = 281.1859 sec (0.1675 sec per sample), RMSE-0 = 23.4587, MAPE-0 = 0.4104, MAE-0 = 5.0845
Training Round 9: loss = 3.078959, time_cost = 290.4096 sec (0.1730 sec per sample), RMSE-0 = 23.2560, MAPE-0 = 0.4078, MAE-0 = 5.0743
Training Round 10: loss = 2.958751, time_cost = 283.3982 sec (0.1688 sec per sample), RMSE-0 = 22.1575, MAPE-0 = 0.4064, MAE-0 = 4.9285
!!! Validation : loss = 2.417172, RMSE-0 = 17.6670, MAPE-0 = 0.4008, MAE-0 = 4.3190
Training Round 11: loss = 3.061051, time_cost = 288.4761 sec (0.1718 sec per sample), RMSE-0 = 23.0626, MAPE-0 = 0.4071, MAE-0 = 5.0469
Training Round 12: loss = 2.912388, time_cost = 299.0846 sec (0.1781 sec per sample), RMSE-0 = 22.6173, MAPE-0 = 0.4059, MAE-0 = 5.0161
Training Round 13: loss = 2.918301, time_cost = 297.1787 sec (0.1770 sec per sample), RMSE-0 = 22.2323, MAPE-0 = 0.4082, MAE-0 = 5.0059
Training Round 14: loss = 2.878379, time_cost = 295.4481 sec (0.1760 sec per sample), RMSE-0 = 22.3595, MAPE-0 = 0.4057, MAE-0 = 5.0210
Training Round 15: loss = 2.866564, time_cost = 286.2868 sec (0.1705 sec per sample), RMSE-0 = 22.2344, MAPE-0 = 0.4044, MAE-0 = 4.9965
!!! Validation : loss = 2.657901, RMSE-0 = 18.6868, MAPE-0 = 0.4017, MAE-0 = 4.5317
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 16: loss = 2.965434, time_cost = 288.5061 sec (0.1718 sec per sample), RMSE-0 = 23.3454, MAPE-0 = 0.4043, MAE-0 = 5.1681
Training Round 17: loss = 2.843743, time_cost = 296.4668 sec (0.1766 sec per sample), RMSE-0 = 22.9798, MAPE-0 = 0.4058, MAE-0 = 5.1495
Training Round 18: loss = 2.841216, time_cost = 299.7251 sec (0.1785 sec per sample), RMSE-0 = 22.6169, MAPE-0 = 0.4040, MAE-0 = 5.1008
Training Round 19: loss = 2.789386, time_cost = 294.9757 sec (0.1757 sec per sample), RMSE-0 = 22.4526, MAPE-0 = 0.4070, MAE-0 = 5.1200
Training Round 20: loss = 2.743548, time_cost = 291.9404 sec (0.1739 sec per sample), RMSE-0 = 21.9204, MAPE-0 = 0.4013, MAE-0 = 5.0453
!!! Validation : loss = 2.421049, RMSE-0 = 21.3146, MAPE-0 = 0.4061, MAE-0 = 4.7251
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 21: loss = 2.685591, time_cost = 277.9047 sec (0.1655 sec per sample), RMSE-0 = 21.4089, MAPE-0 = 0.3992, MAE-0 = 4.9406
Training Round 22: loss = 2.701232, time_cost = 294.0424 sec (0.1751 sec per sample), RMSE-0 = 21.3478, MAPE-0 = 0.3989, MAE-0 = 4.9199
Training Round 23: loss = 2.874703, time_cost = 297.0539 sec (0.1769 sec per sample), RMSE-0 = 23.7734, MAPE-0 = 0.4084, MAE-0 = 5.2460
Training Round 24: loss = 2.715550, time_cost = 294.1214 sec (0.1752 sec per sample), RMSE-0 = 21.9109, MAPE-0 = 0.4026, MAE-0 = 5.0175
Training Round 25: loss = 2.706255, time_cost = 284.0094 sec (0.1692 sec per sample), RMSE-0 = 22.2235, MAPE-0 = 0.3983, MAE-0 = 5.0671
!!! Validation : loss = 2.460527, RMSE-0 = 19.9165, MAPE-0 = 0.4094, MAE-0 = 4.7019
Training Round 26: loss = 2.729086, time_cost = 280.1673 sec (0.1669 sec per sample), RMSE-0 = 23.5423, MAPE-0 = 0.4014, MAE-0 = 5.1642
Training Round 27: loss = 2.809502, time_cost = 295.0052 sec (0.1757 sec per sample), RMSE-0 = 24.0893, MAPE-0 = 0.4047, MAE-0 = 5.2823
Training Round 28: loss = 2.696862, time_cost = 291.3493 sec (0.1735 sec per sample), RMSE-0 = 24.8858, MAPE-0 = 0.4076, MAE-0 = 5.3766
Training Round 29: loss = 2.694295, time_cost = 303.8977 sec (0.1810 sec per sample), RMSE-0 = 22.3028, MAPE-0 = 0.4009, MAE-0 = 5.0400
Training Round 30: loss = 2.674797, time_cost = 296.1753 sec (0.1764 sec per sample), RMSE-0 = 22.6670, MAPE-0 = 0.4022, MAE-0 = 5.1113
!!! Validation : loss = 2.507189, RMSE-0 = 22.1028, MAPE-0 = 0.4223, MAE-0 = 4.9480
Training Round 31: loss = 2.730104, time_cost = 302.7743 sec (0.1803 sec per sample), RMSE-0 = 23.1469, MAPE-0 = 0.4058, MAE-0 = 5.2229
Training Round 32: loss = 2.625866, time_cost = 290.1643 sec (0.1728 sec per sample), RMSE-0 = 23.8028, MAPE-0 = 0.4029, MAE-0 = 5.2619
Training Round 33: loss = 2.573791, time_cost = 288.8729 sec (0.1721 sec per sample), RMSE-0 = 22.8866, MAPE-0 = 0.4073, MAE-0 = 5.2312
Training Round 34: loss = 2.648928, time_cost = 291.0871 sec (0.1734 sec per sample), RMSE-0 = 22.7211, MAPE-0 = 0.3986, MAE-0 = 5.0998
Training Round 35: loss = 2.581608, time_cost = 291.7731 sec (0.1738 sec per sample), RMSE-0 = 21.4067, MAPE-0 = 0.3989, MAE-0 = 4.9719
!!! Validation : loss = 2.513997, RMSE-0 = 24.4055, MAPE-0 = 0.4101, MAE-0 = 5.2303
Training Round 36: loss = 2.531075, time_cost = 302.0840 sec (0.1799 sec per sample), RMSE-0 = 20.9636, MAPE-0 = 0.3924, MAE-0 = 4.8668
Training Round 37: loss = 2.568069, time_cost = 288.4854 sec (0.1718 sec per sample), RMSE-0 = 20.6524, MAPE-0 = 0.3936, MAE-0 = 4.8507
Training Round 38: loss = 2.643675, time_cost = 294.8806 sec (0.1756 sec per sample), RMSE-0 = 23.0376, MAPE-0 = 0.4031, MAE-0 = 5.1949
Training Round 39: loss = 2.644441, time_cost = 296.7664 sec (0.1768 sec per sample), RMSE-0 = 22.0763, MAPE-0 = 0.3984, MAE-0 = 5.0962
Training Round 40: loss = 2.620233, time_cost = 297.6963 sec (0.1773 sec per sample), RMSE-0 = 23.4172, MAPE-0 = 0.4012, MAE-0 = 5.1980
!!! Validation : loss = 2.503185, RMSE-0 = 23.4777, MAPE-0 = 0.4323, MAE-0 = 5.2758
Training Round 41: loss = 2.651360, time_cost = 291.7485 sec (0.1738 sec per sample), RMSE-0 = 24.9581, MAPE-0 = 0.4187, MAE-0 = 5.5780
Training Round 42: loss = 2.543732, time_cost = 295.1199 sec (0.1758 sec per sample), RMSE-0 = 21.7111, MAPE-0 = 0.4057, MAE-0 = 5.0768
Training Round 43: loss = 2.523503, time_cost = 290.6001 sec (0.1731 sec per sample), RMSE-0 = 21.5387, MAPE-0 = 0.3986, MAE-0 = 5.0164
Training Round 44: loss = 2.648023, time_cost = 294.8650 sec (0.1756 sec per sample), RMSE-0 = 23.6697, MAPE-0 = 0.4084, MAE-0 = 5.3418
Training Round 45: loss = 2.489916, time_cost = 294.3019 sec (0.1753 sec per sample), RMSE-0 = 22.1488, MAPE-0 = 0.4086, MAE-0 = 5.1597
!!! Validation : loss = 2.489974, RMSE-0 = 22.6715, MAPE-0 = 0.4254, MAE-0 = 5.1396
Training Round 46: loss = 2.501353, time_cost = 294.5384 sec (0.1754 sec per sample), RMSE-0 = 20.3234, MAPE-0 = 0.3985, MAE-0 = 4.8521
Training Round 47: loss = 2.544960, time_cost = 291.6480 sec (0.1737 sec per sample), RMSE-0 = 23.1821, MAPE-0 = 0.4077, MAE-0 = 5.2157
Training Round 48: loss = 2.553823, time_cost = 301.4249 sec (0.1795 sec per sample), RMSE-0 = 22.0582, MAPE-0 = 0.4020, MAE-0 = 5.1242
Training Round 49: loss = 2.482469, time_cost = 283.2787 sec (0.1687 sec per sample), RMSE-0 = 21.3805, MAPE-0 = 0.4065, MAE-0 = 5.0415
Training Round 50: loss = 2.460972, time_cost = 294.7562 sec (0.1756 sec per sample), RMSE-0 = 22.4346, MAPE-0 = 0.4038, MAE-0 = 5.0966
!!! Validation : loss = 2.348964, RMSE-0 = 25.3934, MAPE-0 = 0.4279, MAE-0 = 5.6002
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 51: loss = 2.547404, time_cost = 287.0147 sec (0.1709 sec per sample), RMSE-0 = 23.5972, MAPE-0 = 0.4114, MAE-0 = 5.3833
Training Round 52: loss = 2.446540, time_cost = 288.1592 sec (0.1716 sec per sample), RMSE-0 = 21.6273, MAPE-0 = 0.4068, MAE-0 = 5.0803
Training Round 53: loss = 2.485671, time_cost = 284.5265 sec (0.1695 sec per sample), RMSE-0 = 22.3829, MAPE-0 = 0.4109, MAE-0 = 5.2121
Training Round 54: loss = 2.569844, time_cost = 290.9219 sec (0.1733 sec per sample), RMSE-0 = 21.6648, MAPE-0 = 0.4073, MAE-0 = 5.1198
Training Round 55: loss = 2.469098, time_cost = 287.2061 sec (0.1711 sec per sample), RMSE-0 = 21.3437, MAPE-0 = 0.4085, MAE-0 = 5.0586
!!! Validation : loss = 2.334290, RMSE-0 = 22.0727, MAPE-0 = 0.4270, MAE-0 = 5.1288
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 56: loss = 2.472384, time_cost = 289.1835 sec (0.1722 sec per sample), RMSE-0 = 21.3901, MAPE-0 = 0.4090, MAE-0 = 5.1053
Training Round 57: loss = 2.526356, time_cost = 287.4645 sec (0.1712 sec per sample), RMSE-0 = 22.5666, MAPE-0 = 0.4135, MAE-0 = 5.2427
Training Round 58: loss = 2.393131, time_cost = 289.4398 sec (0.1724 sec per sample), RMSE-0 = 19.8459, MAPE-0 = 0.4020, MAE-0 = 4.8369
Training Round 59: loss = 2.461674, time_cost = 283.3299 sec (0.1687 sec per sample), RMSE-0 = 20.7190, MAPE-0 = 0.4046, MAE-0 = 4.9649
Training Round 60: loss = 2.441611, time_cost = 285.9633 sec (0.1703 sec per sample), RMSE-0 = 21.1654, MAPE-0 = 0.4076, MAE-0 = 5.0155
!!! Validation : loss = 2.422165, RMSE-0 = 24.4920, MAPE-0 = 0.4416, MAE-0 = 5.6648
Training Round 61: loss = 2.543682, time_cost = 285.0348 sec (0.1698 sec per sample), RMSE-0 = 21.9654, MAPE-0 = 0.4102, MAE-0 = 5.1925
Training Round 62: loss = 2.487680, time_cost = 282.2174 sec (0.1681 sec per sample), RMSE-0 = 22.3841, MAPE-0 = 0.4149, MAE-0 = 5.2648
Training Round 63: loss = 2.419152, time_cost = 284.6779 sec (0.1696 sec per sample), RMSE-0 = 21.8227, MAPE-0 = 0.4212, MAE-0 = 5.2504
Training Round 64: loss = 2.511672, time_cost = 286.0811 sec (0.1704 sec per sample), RMSE-0 = 22.4401, MAPE-0 = 0.4112, MAE-0 = 5.2269
Training Round 65: loss = 2.473664, time_cost = 291.0079 sec (0.1733 sec per sample), RMSE-0 = 22.0728, MAPE-0 = 0.4143, MAE-0 = 5.1905
!!! Validation : loss = 2.354842, RMSE-0 = 21.4024, MAPE-0 = 0.4255, MAE-0 = 5.0967
Training Round 66: loss = 2.387020, time_cost = 283.2827 sec (0.1687 sec per sample), RMSE-0 = 22.3501, MAPE-0 = 0.4130, MAE-0 = 5.1961
Training Round 67: loss = 2.459153, time_cost = 283.3631 sec (0.1688 sec per sample), RMSE-0 = 21.7360, MAPE-0 = 0.4193, MAE-0 = 5.2079
Training Round 68: loss = 2.448462, time_cost = 288.5470 sec (0.1719 sec per sample), RMSE-0 = 21.6573, MAPE-0 = 0.4115, MAE-0 = 5.1424
Training Round 69: loss = 2.477753, time_cost = 289.4612 sec (0.1724 sec per sample), RMSE-0 = 23.3918, MAPE-0 = 0.4240, MAE-0 = 5.4486
Training Round 70: loss = 2.463729, time_cost = 284.1808 sec (0.1693 sec per sample), RMSE-0 = 22.2722, MAPE-0 = 0.4178, MAE-0 = 5.2774
!!! Validation : loss = 2.232340, RMSE-0 = 20.0249, MAPE-0 = 0.4301, MAE-0 = 5.0115
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 71: loss = 2.462301, time_cost = 285.8940 sec (0.1703 sec per sample), RMSE-0 = 22.9983, MAPE-0 = 0.4271, MAE-0 = 5.4322
Training Round 72: loss = 2.376617, time_cost = 288.9532 sec (0.1721 sec per sample), RMSE-0 = 22.3044, MAPE-0 = 0.4248, MAE-0 = 5.3529
Training Round 73: loss = 2.435158, time_cost = 286.9462 sec (0.1709 sec per sample), RMSE-0 = 22.3555, MAPE-0 = 0.4258, MAE-0 = 5.3442
Training Round 74: loss = 2.463367, time_cost = 286.6894 sec (0.1708 sec per sample), RMSE-0 = 22.6692, MAPE-0 = 0.4191, MAE-0 = 5.3076
Training Round 75: loss = 2.415819, time_cost = 298.9914 sec (0.1781 sec per sample), RMSE-0 = 21.7301, MAPE-0 = 0.4212, MAE-0 = 5.2100
!!! Validation : loss = 2.390881, RMSE-0 = 21.7264, MAPE-0 = 0.4323, MAE-0 = 5.0768
Training Round 76: loss = 2.405851, time_cost = 291.8430 sec (0.1738 sec per sample), RMSE-0 = 21.5039, MAPE-0 = 0.4166, MAE-0 = 5.1576
Training Round 77: loss = 2.438457, time_cost = 287.3299 sec (0.1711 sec per sample), RMSE-0 = 22.6664, MAPE-0 = 0.4244, MAE-0 = 5.3449
Training Round 78: loss = 2.414238, time_cost = 288.5176 sec (0.1718 sec per sample), RMSE-0 = 21.3229, MAPE-0 = 0.4175, MAE-0 = 5.1404
Training Round 79: loss = 2.489229, time_cost = 285.8069 sec (0.1702 sec per sample), RMSE-0 = 21.9385, MAPE-0 = 0.4201, MAE-0 = 5.2285
Training Round 80: loss = 2.429956, time_cost = 284.8733 sec (0.1697 sec per sample), RMSE-0 = 21.6557, MAPE-0 = 0.4239, MAE-0 = 5.2456
!!! Validation : loss = 2.261532, RMSE-0 = 19.8354, MAPE-0 = 0.4350, MAE-0 = 4.9371
Training Round 81: loss = 2.413229, time_cost = 284.4409 sec (0.1694 sec per sample), RMSE-0 = 22.2636, MAPE-0 = 0.4206, MAE-0 = 5.2596
Training Round 82: loss = 2.411314, time_cost = 282.9979 sec (0.1686 sec per sample), RMSE-0 = 21.1659, MAPE-0 = 0.4161, MAE-0 = 5.0797
Training Round 83: loss = 2.407794, time_cost = 288.2779 sec (0.1717 sec per sample), RMSE-0 = 21.2708, MAPE-0 = 0.4208, MAE-0 = 5.1678
Training Round 84: loss = 2.377135, time_cost = 297.5423 sec (0.1772 sec per sample), RMSE-0 = 21.1603, MAPE-0 = 0.4268, MAE-0 = 5.2440
Training Round 85: loss = 2.346586, time_cost = 293.1017 sec (0.1746 sec per sample), RMSE-0 = 21.5603, MAPE-0 = 0.4238, MAE-0 = 5.2202
!!! Validation : loss = 2.256761, RMSE-0 = 19.8211, MAPE-0 = 0.4227, MAE-0 = 4.7862
Training Round 86: loss = 2.446416, time_cost = 305.2516 sec (0.1818 sec per sample), RMSE-0 = 21.5203, MAPE-0 = 0.4193, MAE-0 = 5.1528
Training Round 87: loss = 2.363589, time_cost = 305.2478 sec (0.1818 sec per sample), RMSE-0 = 20.5813, MAPE-0 = 0.4179, MAE-0 = 5.0835
Training Round 88: loss = 2.471376, time_cost = 288.1035 sec (0.1716 sec per sample), RMSE-0 = 21.9558, MAPE-0 = 0.4167, MAE-0 = 5.1937
Training Round 89: loss = 2.390917, time_cost = 291.3803 sec (0.1735 sec per sample), RMSE-0 = 21.1126, MAPE-0 = 0.4134, MAE-0 = 5.0660
Training Round 90: loss = 2.442538, time_cost = 304.0371 sec (0.1811 sec per sample), RMSE-0 = 21.6641, MAPE-0 = 0.4163, MAE-0 = 5.1602
!!! Validation : loss = 2.243390, RMSE-0 = 21.7199, MAPE-0 = 0.4304, MAE-0 = 4.9962
Training Round 91: loss = 2.323704, time_cost = 287.6350 sec (0.1713 sec per sample), RMSE-0 = 20.9050, MAPE-0 = 0.4185, MAE-0 = 5.0574
Training Round 92: loss = 2.400448, time_cost = 308.4336 sec (0.1837 sec per sample), RMSE-0 = 21.7640, MAPE-0 = 0.4181, MAE-0 = 5.1453
Training Round 93: loss = 2.410332, time_cost = 297.4311 sec (0.1771 sec per sample), RMSE-0 = 21.4467, MAPE-0 = 0.4193, MAE-0 = 5.1398
Training Round 94: loss = 2.469581, time_cost = 296.5061 sec (0.1766 sec per sample), RMSE-0 = 22.2663, MAPE-0 = 0.4227, MAE-0 = 5.3422
Training Round 95: loss = 2.388082, time_cost = 292.8466 sec (0.1744 sec per sample), RMSE-0 = 21.2158, MAPE-0 = 0.4198, MAE-0 = 5.1276
!!! Validation : loss = 2.481264, RMSE-0 = 19.3614, MAPE-0 = 0.4417, MAE-0 = 4.9494
Training Round 96: loss = 2.391445, time_cost = 285.5074 sec (0.1700 sec per sample), RMSE-0 = 21.3115, MAPE-0 = 0.4222, MAE-0 = 5.1258
Training Round 97: loss = 2.360787, time_cost = 297.8388 sec (0.1774 sec per sample), RMSE-0 = 20.7504, MAPE-0 = 0.4168, MAE-0 = 5.0573
Training Round 98: loss = 2.343491, time_cost = 288.0591 sec (0.1716 sec per sample), RMSE-0 = 21.7142, MAPE-0 = 0.4204, MAE-0 = 5.1230
Training Round 99: loss = 2.419069, time_cost = 290.1329 sec (0.1728 sec per sample), RMSE-0 = 21.4602, MAPE-0 = 0.4210, MAE-0 = 5.1665
Training Round 100: loss = 2.381616, time_cost = 296.0158 sec (0.1763 sec per sample), RMSE-0 = 21.3086, MAPE-0 = 0.4197, MAE-0 = 5.1653
!!! Validation : loss = 2.310780, RMSE-0 = 20.0107, MAPE-0 = 0.4353, MAE-0 = 4.9720
Training Round 101: loss = 2.333108, time_cost = 286.1871 sec (0.1705 sec per sample), RMSE-0 = 21.4978, MAPE-0 = 0.4169, MAE-0 = 5.0945
Training Round 102: loss = 2.411115, time_cost = 287.3180 sec (0.1711 sec per sample), RMSE-0 = 21.5224, MAPE-0 = 0.4189, MAE-0 = 5.1600
Training Round 103: loss = 2.360329, time_cost = 288.1598 sec (0.1716 sec per sample), RMSE-0 = 21.0663, MAPE-0 = 0.4177, MAE-0 = 5.0658
Training Round 104: loss = 2.383793, time_cost = 282.7220 sec (0.1684 sec per sample), RMSE-0 = 21.3974, MAPE-0 = 0.4192, MAE-0 = 5.1266
Training Round 105: loss = 2.425582, time_cost = 290.8067 sec (0.1732 sec per sample), RMSE-0 = 21.8237, MAPE-0 = 0.4191, MAE-0 = 5.1781
!!! Validation : loss = 2.371177, RMSE-0 = 22.1211, MAPE-0 = 0.4245, MAE-0 = 5.2950
Training Round 106: loss = 2.422877, time_cost = 299.1188 sec (0.1782 sec per sample), RMSE-0 = 21.7071, MAPE-0 = 0.4171, MAE-0 = 5.1408
Training Round 107: loss = 2.357163, time_cost = 290.3826 sec (0.1729 sec per sample), RMSE-0 = 21.4916, MAPE-0 = 0.4193, MAE-0 = 5.1069
Training Round 108: loss = 2.391179, time_cost = 299.4680 sec (0.1784 sec per sample), RMSE-0 = 21.4267, MAPE-0 = 0.4210, MAE-0 = 5.1312
Training Round 109: loss = 2.398775, time_cost = 281.0086 sec (0.1674 sec per sample), RMSE-0 = 21.4075, MAPE-0 = 0.4216, MAE-0 = 5.1490
Training Round 110: loss = 2.445627, time_cost = 290.2145 sec (0.1728 sec per sample), RMSE-0 = 21.8016, MAPE-0 = 0.4268, MAE-0 = 5.2242
!!! Validation : loss = 2.203574, RMSE-0 = 20.2009, MAPE-0 = 0.4302, MAE-0 = 4.9553
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 111: loss = 2.345521, time_cost = 294.8895 sec (0.1756 sec per sample), RMSE-0 = 21.1731, MAPE-0 = 0.4168, MAE-0 = 5.0724
Training Round 112: loss = 2.427869, time_cost = 281.3526 sec (0.1676 sec per sample), RMSE-0 = 21.4638, MAPE-0 = 0.4206, MAE-0 = 5.1543
Training Round 113: loss = 2.422495, time_cost = 295.1466 sec (0.1758 sec per sample), RMSE-0 = 21.9684, MAPE-0 = 0.4183, MAE-0 = 5.1410
Training Round 114: loss = 2.336317, time_cost = 297.3941 sec (0.1771 sec per sample), RMSE-0 = 20.9266, MAPE-0 = 0.4201, MAE-0 = 5.0767
Training Round 115: loss = 2.367230, time_cost = 294.4431 sec (0.1754 sec per sample), RMSE-0 = 21.4695, MAPE-0 = 0.4153, MAE-0 = 5.0404
!!! Validation : loss = 2.635847, RMSE-0 = 22.1244, MAPE-0 = 0.4450, MAE-0 = 5.4817
Training Round 116: loss = 2.487310, time_cost = 290.5012 sec (0.1730 sec per sample), RMSE-0 = 21.7540, MAPE-0 = 0.4115, MAE-0 = 5.0944
Training Round 117: loss = 2.506338, time_cost = 293.0047 sec (0.1745 sec per sample), RMSE-0 = 21.4093, MAPE-0 = 0.4158, MAE-0 = 5.0604
Training Round 118: loss = 2.395703, time_cost = 296.0501 sec (0.1763 sec per sample), RMSE-0 = 21.1476, MAPE-0 = 0.4129, MAE-0 = 4.9971
Training Round 119: loss = 2.320756, time_cost = 299.6557 sec (0.1785 sec per sample), RMSE-0 = 20.5178, MAPE-0 = 0.4079, MAE-0 = 4.8636
Training Round 120: loss = 2.402506, time_cost = 286.0754 sec (0.1704 sec per sample), RMSE-0 = 22.1992, MAPE-0 = 0.4164, MAE-0 = 5.1987
!!! Validation : loss = 2.200099, RMSE-0 = 20.2926, MAPE-0 = 0.4361, MAE-0 = 5.0202
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 121: loss = 2.344259, time_cost = 293.6717 sec (0.1749 sec per sample), RMSE-0 = 21.4313, MAPE-0 = 0.4166, MAE-0 = 5.0708
Training Round 122: loss = 2.350277, time_cost = 287.8976 sec (0.1715 sec per sample), RMSE-0 = 21.5607, MAPE-0 = 0.4202, MAE-0 = 5.1117
Training Round 123: loss = 2.437657, time_cost = 294.4754 sec (0.1754 sec per sample), RMSE-0 = 21.5275, MAPE-0 = 0.4191, MAE-0 = 5.1388
Training Round 124: loss = 2.416323, time_cost = 306.9181 sec (0.1828 sec per sample), RMSE-0 = 21.2784, MAPE-0 = 0.4182, MAE-0 = 5.0968
Training Round 125: loss = 2.351449, time_cost = 299.1756 sec (0.1782 sec per sample), RMSE-0 = 20.9775, MAPE-0 = 0.4105, MAE-0 = 4.9773
!!! Validation : loss = 2.328003, RMSE-0 = 20.4383, MAPE-0 = 0.4193, MAE-0 = 4.8871
Training Round 126: loss = 2.332076, time_cost = 292.3199 sec (0.1741 sec per sample), RMSE-0 = 20.5965, MAPE-0 = 0.4135, MAE-0 = 4.9537
Training Round 127: loss = 2.291228, time_cost = 305.0084 sec (0.1817 sec per sample), RMSE-0 = 20.5510, MAPE-0 = 0.4122, MAE-0 = 4.9603
Training Round 128: loss = 2.374550, time_cost = 306.3769 sec (0.1825 sec per sample), RMSE-0 = 21.2730, MAPE-0 = 0.4122, MAE-0 = 5.0389
Training Round 129: loss = 2.428688, time_cost = 291.2234 sec (0.1735 sec per sample), RMSE-0 = 21.4324, MAPE-0 = 0.4187, MAE-0 = 5.1144
Training Round 130: loss = 2.371138, time_cost = 286.1350 sec (0.1704 sec per sample), RMSE-0 = 21.5519, MAPE-0 = 0.4173, MAE-0 = 5.1292
!!! Validation : loss = 2.246864, RMSE-0 = 20.9503, MAPE-0 = 0.4240, MAE-0 = 4.9455
Training Round 131: loss = 2.342618, time_cost = 297.8137 sec (0.1774 sec per sample), RMSE-0 = 21.4987, MAPE-0 = 0.4157, MAE-0 = 5.0394
Training Round 132: loss = 2.365619, time_cost = 295.4291 sec (0.1760 sec per sample), RMSE-0 = 21.4589, MAPE-0 = 0.4156, MAE-0 = 5.0585
Training Round 133: loss = 2.398636, time_cost = 289.0856 sec (0.1722 sec per sample), RMSE-0 = 20.9323, MAPE-0 = 0.4134, MAE-0 = 5.0158
Training Round 134: loss = 2.391340, time_cost = 303.7426 sec (0.1809 sec per sample), RMSE-0 = 21.9935, MAPE-0 = 0.4160, MAE-0 = 5.0942
Training Round 135: loss = 2.443308, time_cost = 287.6573 sec (0.1713 sec per sample), RMSE-0 = 21.8149, MAPE-0 = 0.4150, MAE-0 = 5.1276
!!! Validation : loss = 2.308701, RMSE-0 = 21.3686, MAPE-0 = 0.4382, MAE-0 = 5.0468
Training Round 136: loss = 2.445044, time_cost = 284.3137 sec (0.1693 sec per sample), RMSE-0 = 22.1385, MAPE-0 = 0.4175, MAE-0 = 5.1334
Training Round 137: loss = 2.368210, time_cost = 292.0978 sec (0.1740 sec per sample), RMSE-0 = 22.1073, MAPE-0 = 0.4188, MAE-0 = 5.1645
Training Round 138: loss = 2.327922, time_cost = 288.7339 sec (0.1720 sec per sample), RMSE-0 = 21.8542, MAPE-0 = 0.4191, MAE-0 = 5.1251
Training Round 139: loss = 2.365033, time_cost = 294.2291 sec (0.1752 sec per sample), RMSE-0 = 21.3870, MAPE-0 = 0.4164, MAE-0 = 5.0600
Training Round 140: loss = 2.434917, time_cost = 296.9605 sec (0.1769 sec per sample), RMSE-0 = 22.3016, MAPE-0 = 0.4185, MAE-0 = 5.2032
!!! Validation : loss = 2.227709, RMSE-0 = 20.2334, MAPE-0 = 0.4214, MAE-0 = 4.7697
Training Round 141: loss = 2.369571, time_cost = 287.6817 sec (0.1713 sec per sample), RMSE-0 = 22.3784, MAPE-0 = 0.4170, MAE-0 = 5.1866
Training Round 142: loss = 2.413866, time_cost = 292.1384 sec (0.1740 sec per sample), RMSE-0 = 23.0283, MAPE-0 = 0.4208, MAE-0 = 5.2817
Training Round 143: loss = 2.388657, time_cost = 286.8860 sec (0.1709 sec per sample), RMSE-0 = 22.1837, MAPE-0 = 0.4133, MAE-0 = 5.1005
Training Round 144: loss = 2.437603, time_cost = 295.4538 sec (0.1760 sec per sample), RMSE-0 = 22.0333, MAPE-0 = 0.4179, MAE-0 = 5.1729
Training Round 145: loss = 2.355106, time_cost = 289.0674 sec (0.1722 sec per sample), RMSE-0 = 21.8333, MAPE-0 = 0.4166, MAE-0 = 5.1088
!!! Validation : loss = 2.268053, RMSE-0 = 20.3105, MAPE-0 = 0.4162, MAE-0 = 4.6687
Training Round 146: loss = 2.410316, time_cost = 282.9014 sec (0.1685 sec per sample), RMSE-0 = 22.5481, MAPE-0 = 0.4193, MAE-0 = 5.2173
Training Round 147: loss = 2.401029, time_cost = 282.7729 sec (0.1684 sec per sample), RMSE-0 = 22.8894, MAPE-0 = 0.4153, MAE-0 = 5.1944
Training Round 148: loss = 2.383502, time_cost = 284.8845 sec (0.1697 sec per sample), RMSE-0 = 22.4294, MAPE-0 = 0.4137, MAE-0 = 5.1220
Training Round 149: loss = 2.354735, time_cost = 286.4598 sec (0.1706 sec per sample), RMSE-0 = 22.4107, MAPE-0 = 0.4197, MAE-0 = 5.1703
Training Round 150: loss = 2.375263, time_cost = 286.4631 sec (0.1706 sec per sample), RMSE-0 = 22.0800, MAPE-0 = 0.4178, MAE-0 = 5.1356
!!! Validation : loss = 2.213933, RMSE-0 = 23.4153, MAPE-0 = 0.4395, MAE-0 = 5.3243
Training Round 151: loss = 2.358008, time_cost = 287.3714 sec (0.1712 sec per sample), RMSE-0 = 22.7379, MAPE-0 = 0.4215, MAE-0 = 5.2615
Training Round 152: loss = 2.335616, time_cost = 288.8754 sec (0.1721 sec per sample), RMSE-0 = 22.3853, MAPE-0 = 0.4176, MAE-0 = 5.1357
Training Round 153: loss = 2.382749, time_cost = 287.2095 sec (0.1711 sec per sample), RMSE-0 = 22.6931, MAPE-0 = 0.4193, MAE-0 = 5.2030
Training Round 154: loss = 2.345712, time_cost = 288.0754 sec (0.1716 sec per sample), RMSE-0 = 22.6728, MAPE-0 = 0.4161, MAE-0 = 5.1884
Training Round 155: loss = 2.434493, time_cost = 284.1240 sec (0.1692 sec per sample), RMSE-0 = 22.3703, MAPE-0 = 0.4168, MAE-0 = 5.1742
!!! Validation : loss = 2.303820, RMSE-0 = 19.8981, MAPE-0 = 0.4307, MAE-0 = 4.7938
Training Round 156: loss = 2.356267, time_cost = 299.5702 sec (0.1784 sec per sample), RMSE-0 = 22.1606, MAPE-0 = 0.4148, MAE-0 = 5.1071
Training Round 157: loss = 2.388994, time_cost = 309.6433 sec (0.1844 sec per sample), RMSE-0 = 23.0345, MAPE-0 = 0.4141, MAE-0 = 5.2063
Training Round 158: loss = 2.392862, time_cost = 296.3760 sec (0.1765 sec per sample), RMSE-0 = 23.3997, MAPE-0 = 0.4185, MAE-0 = 5.2832
Training Round 159: loss = 2.359286, time_cost = 300.6672 sec (0.1791 sec per sample), RMSE-0 = 23.1787, MAPE-0 = 0.4187, MAE-0 = 5.2448
Training Round 160: loss = 2.376615, time_cost = 284.8697 sec (0.1697 sec per sample), RMSE-0 = 23.5899, MAPE-0 = 0.4219, MAE-0 = 5.3254
!!! Validation : loss = 2.447031, RMSE-0 = 21.1078, MAPE-0 = 0.4356, MAE-0 = 5.2148
Training Round 161: loss = 2.396831, time_cost = 289.4007 sec (0.1724 sec per sample), RMSE-0 = 22.8823, MAPE-0 = 0.4178, MAE-0 = 5.2041
Training Round 162: loss = 2.366087, time_cost = 302.2768 sec (0.1800 sec per sample), RMSE-0 = 23.1865, MAPE-0 = 0.4198, MAE-0 = 5.2633
Training Round 163: loss = 2.315521, time_cost = 284.6803 sec (0.1696 sec per sample), RMSE-0 = 23.1173, MAPE-0 = 0.4172, MAE-0 = 5.2565
Training Round 164: loss = 2.338980, time_cost = 291.2545 sec (0.1735 sec per sample), RMSE-0 = 22.7239, MAPE-0 = 0.4168, MAE-0 = 5.2038
Training Round 165: loss = 2.405651, time_cost = 298.3852 sec (0.1777 sec per sample), RMSE-0 = 23.9617, MAPE-0 = 0.4189, MAE-0 = 5.3834
!!! Validation : loss = 2.319671, RMSE-0 = 23.6131, MAPE-0 = 0.4282, MAE-0 = 5.2365
Training Round 166: loss = 2.385829, time_cost = 304.4779 sec (0.1813 sec per sample), RMSE-0 = 22.4176, MAPE-0 = 0.4186, MAE-0 = 5.1863
Training Round 167: loss = 2.393093, time_cost = 301.5960 sec (0.1796 sec per sample), RMSE-0 = 22.9322, MAPE-0 = 0.4168, MAE-0 = 5.2237
Training Round 168: loss = 2.417641, time_cost = 295.3135 sec (0.1759 sec per sample), RMSE-0 = 22.7898, MAPE-0 = 0.4184, MAE-0 = 5.2159
Training Round 169: loss = 2.380610, time_cost = 296.2893 sec (0.1765 sec per sample), RMSE-0 = 23.4839, MAPE-0 = 0.4194, MAE-0 = 5.3135
Training Round 170: loss = 2.370438, time_cost = 290.7334 sec (0.1732 sec per sample), RMSE-0 = 23.0401, MAPE-0 = 0.4186, MAE-0 = 5.2530
!!! Validation : loss = 2.303565, RMSE-0 = 24.2080, MAPE-0 = 0.4248, MAE-0 = 5.2174
Training Round 171: loss = 2.374603, time_cost = 294.1384 sec (0.1752 sec per sample), RMSE-0 = 23.3142, MAPE-0 = 0.4210, MAE-0 = 5.3161
Training Round 172: loss = 2.418619, time_cost = 298.7994 sec (0.1780 sec per sample), RMSE-0 = 23.6972, MAPE-0 = 0.4226, MAE-0 = 5.3764
Training Round 173: loss = 2.370674, time_cost = 290.7513 sec (0.1732 sec per sample), RMSE-0 = 24.0784, MAPE-0 = 0.4212, MAE-0 = 5.3708
Training Round 174: loss = 2.339779, time_cost = 299.7703 sec (0.1785 sec per sample), RMSE-0 = 23.4001, MAPE-0 = 0.4150, MAE-0 = 5.2527
Training Round 175: loss = 2.368569, time_cost = 297.2852 sec (0.1771 sec per sample), RMSE-0 = 23.9838, MAPE-0 = 0.4167, MAE-0 = 5.3402
!!! Validation : loss = 2.329065, RMSE-0 = 23.5587, MAPE-0 = 0.4415, MAE-0 = 5.3815
Training Round 176: loss = 2.309553, time_cost = 296.0207 sec (0.1763 sec per sample), RMSE-0 = 23.1709, MAPE-0 = 0.4164, MAE-0 = 5.2396
Training Round 177: loss = 2.328679, time_cost = 289.4761 sec (0.1724 sec per sample), RMSE-0 = 23.3461, MAPE-0 = 0.4154, MAE-0 = 5.2928
Training Round 178: loss = 2.381787, time_cost = 304.3493 sec (0.1813 sec per sample), RMSE-0 = 23.1843, MAPE-0 = 0.4189, MAE-0 = 5.3087
Training Round 179: loss = 2.382369, time_cost = 285.0152 sec (0.1698 sec per sample), RMSE-0 = 24.1355, MAPE-0 = 0.4155, MAE-0 = 5.3543
Training Round 180: loss = 2.348809, time_cost = 302.0902 sec (0.1799 sec per sample), RMSE-0 = 24.3115, MAPE-0 = 0.4161, MAE-0 = 5.3967
!!! Validation : loss = 2.169350, RMSE-0 = 22.7530, MAPE-0 = 0.4289, MAE-0 = 5.0464
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 181: loss = 2.317251, time_cost = 281.5374 sec (0.1677 sec per sample), RMSE-0 = 23.6988, MAPE-0 = 0.4174, MAE-0 = 5.2902
Training Round 182: loss = 2.307182, time_cost = 287.0365 sec (0.1710 sec per sample), RMSE-0 = 23.5917, MAPE-0 = 0.4184, MAE-0 = 5.3205
Training Round 183: loss = 2.380428, time_cost = 297.8870 sec (0.1774 sec per sample), RMSE-0 = 23.7208, MAPE-0 = 0.4204, MAE-0 = 5.3457
Training Round 184: loss = 2.366302, time_cost = 295.4653 sec (0.1760 sec per sample), RMSE-0 = 23.5612, MAPE-0 = 0.4203, MAE-0 = 5.2972
Training Round 185: loss = 2.387124, time_cost = 287.1895 sec (0.1710 sec per sample), RMSE-0 = 23.1899, MAPE-0 = 0.4182, MAE-0 = 5.2602
!!! Validation : loss = 2.113469, RMSE-0 = 22.1580, MAPE-0 = 0.4233, MAE-0 = 5.0111
Model: model_save/20220410_19_10_28.pth has been saved since it achieves smaller loss.
Training Round 186: loss = 2.337708, time_cost = 289.9129 sec (0.1727 sec per sample), RMSE-0 = 23.7118, MAPE-0 = 0.4175, MAE-0 = 5.2938
Training Round 187: loss = 2.357175, time_cost = 299.8289 sec (0.1786 sec per sample), RMSE-0 = 23.7048, MAPE-0 = 0.4204, MAE-0 = 5.3128
Training Round 188: loss = 2.408687, time_cost = 284.3692 sec (0.1694 sec per sample), RMSE-0 = 23.5584, MAPE-0 = 0.4190, MAE-0 = 5.2858
Training Round 189: loss = 2.324738, time_cost = 292.5121 sec (0.1742 sec per sample), RMSE-0 = 23.3342, MAPE-0 = 0.4204, MAE-0 = 5.2939
Training Round 190: loss = 2.452908, time_cost = 292.5287 sec (0.1742 sec per sample), RMSE-0 = 23.9330, MAPE-0 = 0.4204, MAE-0 = 5.3650
!!! Validation : loss = 2.307713, RMSE-0 = 23.7123, MAPE-0 = 0.4337, MAE-0 = 5.2246
Training Round 191: loss = 2.322691, time_cost = 295.6329 sec (0.1761 sec per sample), RMSE-0 = 23.1458, MAPE-0 = 0.4171, MAE-0 = 5.2037
Training Round 192: loss = 2.331716, time_cost = 291.5804 sec (0.1737 sec per sample), RMSE-0 = 22.8775, MAPE-0 = 0.4146, MAE-0 = 5.1730
Training Round 193: loss = 2.389033, time_cost = 300.7190 sec (0.1791 sec per sample), RMSE-0 = 23.5978, MAPE-0 = 0.4208, MAE-0 = 5.2919
Training Round 194: loss = 2.357547, time_cost = 307.2064 sec (0.1830 sec per sample), RMSE-0 = 22.7237, MAPE-0 = 0.4167, MAE-0 = 5.1884
Training Round 195: loss = 2.398405, time_cost = 294.0859 sec (0.1752 sec per sample), RMSE-0 = 22.9926, MAPE-0 = 0.4195, MAE-0 = 5.2599
!!! Validation : loss = 2.167117, RMSE-0 = 22.9035, MAPE-0 = 0.4237, MAE-0 = 5.0698
Training Round 196: loss = 2.348634, time_cost = 306.5187 sec (0.1826 sec per sample), RMSE-0 = 23.8920, MAPE-0 = 0.4205, MAE-0 = 5.3790
Training Round 197: loss = 2.363602, time_cost = 291.4146 sec (0.1736 sec per sample), RMSE-0 = 23.7272, MAPE-0 = 0.4192, MAE-0 = 5.3658
Training Round 198: loss = 2.318150, time_cost = 291.5119 sec (0.1736 sec per sample), RMSE-0 = 22.6638, MAPE-0 = 0.4122, MAE-0 = 5.1424
Training Round 199: loss = 2.378240, time_cost = 297.6016 sec (0.1772 sec per sample), RMSE-0 = 23.4845, MAPE-0 = 0.4172, MAE-0 = 5.2962
Training Round 200: loss = 2.306825, time_cost = 286.3159 sec (0.1705 sec per sample), RMSE-0 = 23.3244, MAPE-0 = 0.4182, MAE-0 = 5.2543
!!! Validation : loss = 2.249015, RMSE-0 = 23.3880, MAPE-0 = 0.4397, MAE-0 = 5.2749
> Training finished.

> device: cuda:2
> Loading model_save/20220410_19_10_28.pth
> Model Structure:
GallatExt(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=16, bias=False)
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(64, 64)
      )
    )
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=64, out_features=1, bias=True)
    (Wa): Linear(in_features=64, out_features=64, bias=False)
    (att_out_fc_l): Linear(in_features=64, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=64, out_features=1, bias=False)
  )
)
> Model sent to cuda:2
> Loading DataSet from data/ny2016_0101to0331/
> Total Hours: 2184, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Validation batches: 6, Test batches: 11
tune = True, ref_extent = -1.00
num_heads = 1
> Metrics Evaluations for Validation Set:
Demand:
RMSE-0 = 109.8971, RMSE-3 = 144.5304, RMSE-5 = 146.0231
MAPE-0 = 0.6304, MAPE-3 = 0.5425, MAPE-5 = 0.4291
MAE-0 = 27.6471, MAE-3 = 47.2662, MAE-5 = 52.9087
OD:
RMSE-0 = 22.2250, RMSE-3 = 37.0983, RMSE-5 = 42.3081
MAPE-0 = 0.4221, MAPE-3 = 0.3739, MAPE-5 = 0.3461
MAE-0 = 5.0345, MAE-3 = 12.6531, MAE-5 = 15.8842
> Metrics Evaluations for Test Set:
Demand:
RMSE-0 = 87.7583, RMSE-3 = 116.2177, RMSE-5 = 124.2662
MAPE-0 = 0.4111, MAPE-3 = 0.3358, MAPE-5 = 0.3033
MAE-0 = 26.8361, MAE-3 = 46.1147, MAE-5 = 52.3074
OD:
RMSE-0 = 20.5556, RMSE-3 = 35.2306, RMSE-5 = 40.3246
MAPE-0 = 0.4037, MAPE-3 = 0.3725, MAPE-5 = 0.3498
MAE-0 = 4.9357, MAE-3 = 12.5165, MAE-5 = 15.6756
> Evaluation finished.
