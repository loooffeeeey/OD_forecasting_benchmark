{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import dgl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import *\n",
    "# 读取数据\n",
    "data_path = './data_pro/'\n",
    "graph_path = './data_ori/'\n",
    "print('loading data...')\n",
    "# data = np.load(data_path + 'data.npz')\n",
    "# print(data.files)\n",
    "# xc = data['closeness']\n",
    "# xt = data['trend']\n",
    "# xp = data['period']\n",
    "# label = data['prediction']\n",
    "xc = np.load(data_path + 'data_closeness.npy')\n",
    "print(xc.shape)\n",
    "xt = np.load(data_path + 'data_trend.npy')\n",
    "print(xt.shape)\n",
    "xp = np.load(data_path + 'data_period.npy')\n",
    "label = np.load(data_path + 'data_prediction.npy')\n",
    "\n",
    "# 读取eoGraph.dgl\n",
    "geoGraph = dgl.load_graphs(graph_path + 'geoGraph.dgl')[0][0]\n",
    "adj = geoGraph.adjacency_matrix()\n",
    "print('loading data finished')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 将数据转换为tensor\n",
    "xc = torch.from_numpy(xc)\n",
    "xt = torch.from_numpy(xt)\n",
    "xp = torch.from_numpy(xp)\n",
    "label = torch.from_numpy(label)\n",
    "# adj = torch.from_numpy(adj)\n",
    "\n",
    "# 定义dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, xc, xt, xp, label):\n",
    "        self.xc = xc\n",
    "        self.xt = xt\n",
    "        self.xp = xp\n",
    "        self.label = label\n",
    "    def __getitem__(self, index):\n",
    "        return self.xc[index], self.xt[index], self.xp[index], label\n",
    "    def __len__(self):\n",
    "        return len(self.xc)\n",
    "\n",
    "# 定义dataloder\n",
    "train_dataset = MyDataset(xc, xt, xp, label)\n",
    "#分割数据集\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = int(0.1 * len(train_dataset))\n",
    "test_size = len(train_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 定义模型\n",
    "model = STDGL(in_channels = 361, out_channels = 361)\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 定义early stopping 满足条件时停止训练并保存模型\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "    # 如果val_loss下降则保存模型\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        # 如果val_loss没有下降则计数器+1\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            # 如果计数器达到patience则停止训练\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        # 如果val_loss下降则保存模型\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    # 保存模型\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(self.best_score, val_loss))\n",
    "        torch.save(model.state_dict(), './checkpoint.pt')\n",
    "        self.best_score = val_loss\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "# 训练\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (xc, xt, xp, label) in enumerate(train_loader):\n",
    "        xc, xt, xp, label = xc.to(device), xt.to(device), xp.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xc, xt, xp, adj)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 每10个batch打印一次loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(xc), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# 验证\n",
    "def val(model, device, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xc, xt, xp, label in val_loader:\n",
    "            xc, xt, xp, label = xc.to(device), xt.to(device), xp.to(device), label.to(device)\n",
    "            output = model(xc, xt, xp, adj)\n",
    "            val_loss += criterion(output, label).item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    print('Val set: Average loss: {:.4f}'.format(val_loss))\n",
    "    # 满足条件时停止训练并保存模型\n",
    "    early_stopping(val_loss, model)\n",
    "            \n",
    "# 测试\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xc, xt, xp, label in test_loader:\n",
    "            xc, xt, xp, label = xc.to(device), xt.to(device), xp.to(device), label.to(device)\n",
    "            output = model(xc, xt, xp, adj)\n",
    "            test_loss += criterion(output, label).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "# 训练模型\n",
    "print('start training...')\n",
    "for epoch in range(1, 10):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    val(model, device, val_loader)\n",
    "test(model, device, val_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
