> Seed: 66666
> device: cuda:0
> Loading DataSet from data/dc2017_0101to0331/
> Total Hours: 2136, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Training batches: 51, Validation batches: 6
> Initializing the Training Model: GallatExtFull, Train type = normal
> Model Structure:
GallatExtFull(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=16, bias=False)
    (bn): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
    )
    (bn): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=640, out_features=1, bias=True)
    (Wa): Linear(in_features=640, out_features=640, bias=False)
    (att_out_fc_l): Linear(in_features=640, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=640, out_features=1, bias=False)
  )
)
> Constructing the Optimizer: ADAM
> Using SmoothL1Loss as the Loss Function.
> Model sent to cuda:0

learning_rate = 0.01, epochs = 200, num_workers = 20
eval_freq = 5, batch_size = 32, optimizer = ADAM
tune = True, use_AR=None, ref_extent = -1.00

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 12.277857, time_cost = 138.7336 sec (0.0851 sec per sample), RMSE-0 = 327.9883, MAPE-0 = 4.1608, MAE-0 = 47.8383
Training Round 2: loss = 3.089393, time_cost = 141.0485 sec (0.0865 sec per sample), RMSE-0 = 10.5807, MAPE-0 = 0.4494, MAE-0 = 3.2607
Training Round 3: loss = 2.568783, time_cost = 139.8171 sec (0.0857 sec per sample), RMSE-0 = 9.3040, MAPE-0 = 0.4219, MAE-0 = 2.9474
Training Round 4: loss = 2.348872, time_cost = 140.8358 sec (0.0863 sec per sample), RMSE-0 = 8.6962, MAPE-0 = 0.4122, MAE-0 = 2.8092
Training Round 5: loss = 2.319336, time_cost = 137.4281 sec (0.0843 sec per sample), RMSE-0 = 8.8707, MAPE-0 = 0.4118, MAE-0 = 2.8452
!!! Validation : loss = 2.867672, RMSE-0 = 10.8122, MAPE-0 = 0.4249, MAE-0 = 3.0662
Training Round 6: loss = 2.146060, time_cost = 137.8002 sec (0.0845 sec per sample), RMSE-0 = 8.6380, MAPE-0 = 0.4023, MAE-0 = 2.7516
Training Round 7: loss = 2.230755, time_cost = 141.8025 sec (0.0869 sec per sample), RMSE-0 = 9.5558, MAPE-0 = 0.4134, MAE-0 = 2.9446
Training Round 8: loss = 1.981790, time_cost = 138.0414 sec (0.0846 sec per sample), RMSE-0 = 8.3029, MAPE-0 = 0.3923, MAE-0 = 2.6454
Training Round 9: loss = 1.917844, time_cost = 139.3599 sec (0.0854 sec per sample), RMSE-0 = 8.5144, MAPE-0 = 0.3974, MAE-0 = 2.7109
Training Round 10: loss = 1.928558, time_cost = 138.9923 sec (0.0852 sec per sample), RMSE-0 = 8.3320, MAPE-0 = 0.3924, MAE-0 = 2.6885
!!! Validation : loss = 2.177491, RMSE-0 = 8.6432, MAPE-0 = 0.4011, MAE-0 = 2.6624
Training Round 11: loss = 1.844803, time_cost = 139.1439 sec (0.0853 sec per sample), RMSE-0 = 7.8548, MAPE-0 = 0.3885, MAE-0 = 2.5838
Training Round 12: loss = 1.878586, time_cost = 139.9618 sec (0.0858 sec per sample), RMSE-0 = 8.2470, MAPE-0 = 0.3885, MAE-0 = 2.6523
Training Round 13: loss = 1.850273, time_cost = 136.6220 sec (0.0838 sec per sample), RMSE-0 = 8.1037, MAPE-0 = 0.3906, MAE-0 = 2.6382
Training Round 14: loss = 1.855179, time_cost = 147.3777 sec (0.0904 sec per sample), RMSE-0 = 8.3109, MAPE-0 = 0.3884, MAE-0 = 2.6531
Training Round 15: loss = 1.785652, time_cost = 140.8091 sec (0.0863 sec per sample), RMSE-0 = 7.6687, MAPE-0 = 0.3844, MAE-0 = 2.5491
!!! Validation : loss = 2.162541, RMSE-0 = 7.6316, MAPE-0 = 0.3917, MAE-0 = 2.6006
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 16: loss = 1.813869, time_cost = 139.1187 sec (0.0853 sec per sample), RMSE-0 = 7.8142, MAPE-0 = 0.3843, MAE-0 = 2.5796
Training Round 17: loss = 1.856790, time_cost = 141.4068 sec (0.0867 sec per sample), RMSE-0 = 8.1839, MAPE-0 = 0.3885, MAE-0 = 2.6573
Training Round 18: loss = 1.782220, time_cost = 138.4326 sec (0.0849 sec per sample), RMSE-0 = 7.5863, MAPE-0 = 0.3834, MAE-0 = 2.5438
Training Round 19: loss = 1.783541, time_cost = 137.5846 sec (0.0844 sec per sample), RMSE-0 = 7.6687, MAPE-0 = 0.3827, MAE-0 = 2.5530
Training Round 20: loss = 1.821816, time_cost = 147.8606 sec (0.0907 sec per sample), RMSE-0 = 7.9688, MAPE-0 = 0.3844, MAE-0 = 2.5933
!!! Validation : loss = 1.864858, RMSE-0 = 7.6465, MAPE-0 = 0.3892, MAE-0 = 2.5828
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 21: loss = 1.740689, time_cost = 147.7698 sec (0.0906 sec per sample), RMSE-0 = 7.2514, MAPE-0 = 0.3801, MAE-0 = 2.4830
Training Round 22: loss = 1.788442, time_cost = 139.5652 sec (0.0856 sec per sample), RMSE-0 = 7.5234, MAPE-0 = 0.3800, MAE-0 = 2.5164
Training Round 23: loss = 1.789508, time_cost = 138.1808 sec (0.0847 sec per sample), RMSE-0 = 7.5256, MAPE-0 = 0.3822, MAE-0 = 2.5420
Training Round 24: loss = 1.723451, time_cost = 137.3234 sec (0.0842 sec per sample), RMSE-0 = 7.2492, MAPE-0 = 0.3792, MAE-0 = 2.4659
Training Round 25: loss = 1.702903, time_cost = 146.6621 sec (0.0899 sec per sample), RMSE-0 = 7.1822, MAPE-0 = 0.3779, MAE-0 = 2.4575
!!! Validation : loss = 1.960598, RMSE-0 = 7.5617, MAPE-0 = 0.3916, MAE-0 = 2.6125
Training Round 26: loss = 1.800412, time_cost = 147.4793 sec (0.0904 sec per sample), RMSE-0 = 7.6387, MAPE-0 = 0.3807, MAE-0 = 2.5371
Training Round 27: loss = 1.701149, time_cost = 147.7514 sec (0.0906 sec per sample), RMSE-0 = 7.1098, MAPE-0 = 0.3775, MAE-0 = 2.4502
Training Round 28: loss = 1.829792, time_cost = 154.6054 sec (0.0948 sec per sample), RMSE-0 = 8.0277, MAPE-0 = 0.3835, MAE-0 = 2.6059
Training Round 29: loss = 1.685009, time_cost = 151.2049 sec (0.0927 sec per sample), RMSE-0 = 7.1168, MAPE-0 = 0.3788, MAE-0 = 2.4493
Training Round 30: loss = 1.786509, time_cost = 141.7354 sec (0.0869 sec per sample), RMSE-0 = 7.6950, MAPE-0 = 0.3801, MAE-0 = 2.5426
!!! Validation : loss = 2.019553, RMSE-0 = 7.0661, MAPE-0 = 0.3868, MAE-0 = 2.4882
Training Round 31: loss = 1.701702, time_cost = 143.4276 sec (0.0879 sec per sample), RMSE-0 = 7.1739, MAPE-0 = 0.3783, MAE-0 = 2.4651
Training Round 32: loss = 1.791414, time_cost = 139.7388 sec (0.0857 sec per sample), RMSE-0 = 7.7692, MAPE-0 = 0.3805, MAE-0 = 2.5736
Training Round 33: loss = 1.715897, time_cost = 139.2564 sec (0.0854 sec per sample), RMSE-0 = 7.1922, MAPE-0 = 0.3812, MAE-0 = 2.4756
Training Round 34: loss = 1.760401, time_cost = 138.7437 sec (0.0851 sec per sample), RMSE-0 = 7.2884, MAPE-0 = 0.3793, MAE-0 = 2.4897
Training Round 35: loss = 1.720723, time_cost = 138.0845 sec (0.0847 sec per sample), RMSE-0 = 7.2068, MAPE-0 = 0.3802, MAE-0 = 2.4836
!!! Validation : loss = 2.214752, RMSE-0 = 7.5698, MAPE-0 = 0.3881, MAE-0 = 2.5232
Training Round 36: loss = 1.691948, time_cost = 145.7649 sec (0.0894 sec per sample), RMSE-0 = 7.1105, MAPE-0 = 0.3784, MAE-0 = 2.4448
Training Round 37: loss = 1.678313, time_cost = 141.1962 sec (0.0866 sec per sample), RMSE-0 = 6.9921, MAPE-0 = 0.3776, MAE-0 = 2.4359
Training Round 38: loss = 1.631054, time_cost = 143.6160 sec (0.0881 sec per sample), RMSE-0 = 6.8241, MAPE-0 = 0.3764, MAE-0 = 2.3963
Training Round 39: loss = 1.650698, time_cost = 140.3591 sec (0.0861 sec per sample), RMSE-0 = 7.0028, MAPE-0 = 0.3759, MAE-0 = 2.4199
Training Round 40: loss = 1.638022, time_cost = 139.3284 sec (0.0854 sec per sample), RMSE-0 = 6.9332, MAPE-0 = 0.3759, MAE-0 = 2.4122
!!! Validation : loss = 1.987778, RMSE-0 = 7.1750, MAPE-0 = 0.3936, MAE-0 = 2.5266
Training Round 41: loss = 1.682597, time_cost = 138.3358 sec (0.0848 sec per sample), RMSE-0 = 7.0449, MAPE-0 = 0.3771, MAE-0 = 2.4336
Training Round 42: loss = 1.649509, time_cost = 137.8431 sec (0.0845 sec per sample), RMSE-0 = 7.0637, MAPE-0 = 0.3767, MAE-0 = 2.4282
Training Round 43: loss = 1.733181, time_cost = 137.9634 sec (0.0846 sec per sample), RMSE-0 = 7.5203, MAPE-0 = 0.3803, MAE-0 = 2.5298
Training Round 44: loss = 1.613186, time_cost = 149.5439 sec (0.0917 sec per sample), RMSE-0 = 6.8774, MAPE-0 = 0.3754, MAE-0 = 2.4023
Training Round 45: loss = 1.628740, time_cost = 148.1910 sec (0.0909 sec per sample), RMSE-0 = 6.9800, MAPE-0 = 0.3752, MAE-0 = 2.4135
!!! Validation : loss = 1.819115, RMSE-0 = 6.6200, MAPE-0 = 0.3838, MAE-0 = 2.4129
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 46: loss = 1.625793, time_cost = 146.9339 sec (0.0901 sec per sample), RMSE-0 = 6.8991, MAPE-0 = 0.3764, MAE-0 = 2.4188
Training Round 47: loss = 1.662216, time_cost = 148.6227 sec (0.0911 sec per sample), RMSE-0 = 7.0674, MAPE-0 = 0.3778, MAE-0 = 2.4479
Training Round 48: loss = 1.611473, time_cost = 150.0564 sec (0.0920 sec per sample), RMSE-0 = 6.9903, MAPE-0 = 0.3760, MAE-0 = 2.4220
Training Round 49: loss = 1.590775, time_cost = 149.2999 sec (0.0915 sec per sample), RMSE-0 = 6.7499, MAPE-0 = 0.3749, MAE-0 = 2.3845
Training Round 50: loss = 1.603961, time_cost = 147.6056 sec (0.0905 sec per sample), RMSE-0 = 6.8817, MAPE-0 = 0.3753, MAE-0 = 2.3982
!!! Validation : loss = 1.838051, RMSE-0 = 6.7154, MAPE-0 = 0.3846, MAE-0 = 2.4118
Training Round 51: loss = 1.649714, time_cost = 149.5524 sec (0.0917 sec per sample), RMSE-0 = 6.9375, MAPE-0 = 0.3774, MAE-0 = 2.4345
Training Round 52: loss = 1.600294, time_cost = 148.1269 sec (0.0908 sec per sample), RMSE-0 = 6.7739, MAPE-0 = 0.3752, MAE-0 = 2.3829
Training Round 53: loss = 1.618580, time_cost = 156.2260 sec (0.0958 sec per sample), RMSE-0 = 6.8417, MAPE-0 = 0.3768, MAE-0 = 2.4009
Training Round 54: loss = 1.603095, time_cost = 148.4888 sec (0.0910 sec per sample), RMSE-0 = 6.8246, MAPE-0 = 0.3751, MAE-0 = 2.3938
Training Round 55: loss = 1.596323, time_cost = 150.2861 sec (0.0921 sec per sample), RMSE-0 = 6.8428, MAPE-0 = 0.3752, MAE-0 = 2.4015
!!! Validation : loss = 1.840526, RMSE-0 = 7.2740, MAPE-0 = 0.3865, MAE-0 = 2.4765
Training Round 56: loss = 1.627394, time_cost = 149.9694 sec (0.0919 sec per sample), RMSE-0 = 7.0555, MAPE-0 = 0.3764, MAE-0 = 2.4344
Training Round 57: loss = 1.654940, time_cost = 159.8562 sec (0.0980 sec per sample), RMSE-0 = 7.0885, MAPE-0 = 0.3771, MAE-0 = 2.4448
Training Round 58: loss = 1.584654, time_cost = 151.7426 sec (0.0930 sec per sample), RMSE-0 = 6.7880, MAPE-0 = 0.3747, MAE-0 = 2.3928
Training Round 59: loss = 1.567481, time_cost = 144.8083 sec (0.0888 sec per sample), RMSE-0 = 6.7560, MAPE-0 = 0.3740, MAE-0 = 2.3795
Training Round 60: loss = 1.583668, time_cost = 138.1558 sec (0.0847 sec per sample), RMSE-0 = 7.0852, MAPE-0 = 0.3756, MAE-0 = 2.4213
!!! Validation : loss = 1.820742, RMSE-0 = 6.8119, MAPE-0 = 0.3854, MAE-0 = 2.4251
Training Round 61: loss = 1.587034, time_cost = 141.3183 sec (0.0866 sec per sample), RMSE-0 = 6.8822, MAPE-0 = 0.3771, MAE-0 = 2.4100
Training Round 62: loss = 1.565451, time_cost = 137.9675 sec (0.0846 sec per sample), RMSE-0 = 6.6564, MAPE-0 = 0.3739, MAE-0 = 2.3708
Training Round 63: loss = 1.562025, time_cost = 138.9724 sec (0.0852 sec per sample), RMSE-0 = 6.6708, MAPE-0 = 0.3755, MAE-0 = 2.3766
Training Round 64: loss = 1.634134, time_cost = 141.4447 sec (0.0867 sec per sample), RMSE-0 = 7.1340, MAPE-0 = 0.3771, MAE-0 = 2.4594
Training Round 65: loss = 1.586285, time_cost = 142.1159 sec (0.0871 sec per sample), RMSE-0 = 6.7770, MAPE-0 = 0.3746, MAE-0 = 2.3905
!!! Validation : loss = 2.100690, RMSE-0 = 6.8012, MAPE-0 = 0.3790, MAE-0 = 2.3924
Training Round 66: loss = 1.547808, time_cost = 138.7024 sec (0.0850 sec per sample), RMSE-0 = 6.6563, MAPE-0 = 0.3743, MAE-0 = 2.3621
Training Round 67: loss = 1.580961, time_cost = 138.8350 sec (0.0851 sec per sample), RMSE-0 = 6.7763, MAPE-0 = 0.3757, MAE-0 = 2.3934
Training Round 68: loss = 1.575959, time_cost = 137.2975 sec (0.0842 sec per sample), RMSE-0 = 6.8273, MAPE-0 = 0.3755, MAE-0 = 2.4033
Training Round 69: loss = 1.562617, time_cost = 141.6770 sec (0.0869 sec per sample), RMSE-0 = 6.6930, MAPE-0 = 0.3746, MAE-0 = 2.3781
Training Round 70: loss = 1.585257, time_cost = 138.3514 sec (0.0848 sec per sample), RMSE-0 = 6.8031, MAPE-0 = 0.3748, MAE-0 = 2.3890
!!! Validation : loss = 1.736264, RMSE-0 = 6.8526, MAPE-0 = 0.3874, MAE-0 = 2.4475
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 71: loss = 1.571107, time_cost = 144.2987 sec (0.0885 sec per sample), RMSE-0 = 6.9099, MAPE-0 = 0.3755, MAE-0 = 2.4125
Training Round 72: loss = 1.582518, time_cost = 138.0909 sec (0.0847 sec per sample), RMSE-0 = 6.7734, MAPE-0 = 0.3745, MAE-0 = 2.3872
Training Round 73: loss = 1.600503, time_cost = 137.0417 sec (0.0840 sec per sample), RMSE-0 = 6.9823, MAPE-0 = 0.3767, MAE-0 = 2.4225
Training Round 74: loss = 1.517301, time_cost = 137.1837 sec (0.0841 sec per sample), RMSE-0 = 6.7917, MAPE-0 = 0.3738, MAE-0 = 2.3749
Training Round 75: loss = 1.594141, time_cost = 149.7343 sec (0.0918 sec per sample), RMSE-0 = 6.8902, MAPE-0 = 0.3762, MAE-0 = 2.4046
!!! Validation : loss = 1.761793, RMSE-0 = 6.8823, MAPE-0 = 0.3839, MAE-0 = 2.4105
Training Round 76: loss = 1.584694, time_cost = 138.3977 sec (0.0849 sec per sample), RMSE-0 = 7.1364, MAPE-0 = 0.3772, MAE-0 = 2.4523
Training Round 77: loss = 1.563515, time_cost = 144.2987 sec (0.0885 sec per sample), RMSE-0 = 6.7153, MAPE-0 = 0.3747, MAE-0 = 2.3801
Training Round 78: loss = 1.546781, time_cost = 136.6658 sec (0.0838 sec per sample), RMSE-0 = 6.6943, MAPE-0 = 0.3746, MAE-0 = 2.3720
Training Round 79: loss = 1.549173, time_cost = 139.0804 sec (0.0853 sec per sample), RMSE-0 = 6.6903, MAPE-0 = 0.3740, MAE-0 = 2.3754
Training Round 80: loss = 1.590271, time_cost = 139.0629 sec (0.0853 sec per sample), RMSE-0 = 6.8215, MAPE-0 = 0.3747, MAE-0 = 2.3894
!!! Validation : loss = 1.728536, RMSE-0 = 6.5271, MAPE-0 = 0.3803, MAE-0 = 2.3501
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 81: loss = 1.553203, time_cost = 137.7567 sec (0.0845 sec per sample), RMSE-0 = 6.5852, MAPE-0 = 0.3738, MAE-0 = 2.3601
Training Round 82: loss = 1.537895, time_cost = 139.3626 sec (0.0854 sec per sample), RMSE-0 = 6.6438, MAPE-0 = 0.3741, MAE-0 = 2.3610
Training Round 83: loss = 1.583521, time_cost = 136.6707 sec (0.0838 sec per sample), RMSE-0 = 6.8715, MAPE-0 = 0.3743, MAE-0 = 2.4008
Training Round 84: loss = 1.586026, time_cost = 139.6494 sec (0.0856 sec per sample), RMSE-0 = 6.8475, MAPE-0 = 0.3752, MAE-0 = 2.3966
Training Round 85: loss = 1.611036, time_cost = 136.0870 sec (0.0834 sec per sample), RMSE-0 = 6.8897, MAPE-0 = 0.3751, MAE-0 = 2.3976
!!! Validation : loss = 1.776916, RMSE-0 = 6.7557, MAPE-0 = 0.3806, MAE-0 = 2.4164
Training Round 86: loss = 1.550150, time_cost = 139.7804 sec (0.0857 sec per sample), RMSE-0 = 6.8034, MAPE-0 = 0.3744, MAE-0 = 2.3911
Training Round 87: loss = 1.552085, time_cost = 139.8529 sec (0.0857 sec per sample), RMSE-0 = 6.8289, MAPE-0 = 0.3754, MAE-0 = 2.3956
Training Round 88: loss = 1.546617, time_cost = 138.1992 sec (0.0847 sec per sample), RMSE-0 = 6.9053, MAPE-0 = 0.3752, MAE-0 = 2.4063
Training Round 89: loss = 1.523054, time_cost = 140.2398 sec (0.0860 sec per sample), RMSE-0 = 6.7194, MAPE-0 = 0.3741, MAE-0 = 2.3698
Training Round 90: loss = 1.595587, time_cost = 137.8035 sec (0.0845 sec per sample), RMSE-0 = 6.7672, MAPE-0 = 0.3746, MAE-0 = 2.3853
!!! Validation : loss = 1.700097, RMSE-0 = 6.5817, MAPE-0 = 0.3810, MAE-0 = 2.3837
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 91: loss = 1.567713, time_cost = 144.4317 sec (0.0886 sec per sample), RMSE-0 = 6.7756, MAPE-0 = 0.3737, MAE-0 = 2.3797
Training Round 92: loss = 1.538304, time_cost = 139.7775 sec (0.0857 sec per sample), RMSE-0 = 6.6444, MAPE-0 = 0.3741, MAE-0 = 2.3594
Training Round 93: loss = 1.563326, time_cost = 139.6952 sec (0.0857 sec per sample), RMSE-0 = 6.6583, MAPE-0 = 0.3739, MAE-0 = 2.3665
Training Round 94: loss = 1.544350, time_cost = 138.0133 sec (0.0846 sec per sample), RMSE-0 = 6.6782, MAPE-0 = 0.3740, MAE-0 = 2.3612
Training Round 95: loss = 1.567211, time_cost = 140.8392 sec (0.0864 sec per sample), RMSE-0 = 6.7440, MAPE-0 = 0.3731, MAE-0 = 2.3736
!!! Validation : loss = 1.727666, RMSE-0 = 6.5412, MAPE-0 = 0.3769, MAE-0 = 2.3550
Training Round 96: loss = 1.540604, time_cost = 144.9285 sec (0.0889 sec per sample), RMSE-0 = 6.6728, MAPE-0 = 0.3730, MAE-0 = 2.3527
Training Round 97: loss = 1.547911, time_cost = 143.7404 sec (0.0881 sec per sample), RMSE-0 = 6.7054, MAPE-0 = 0.3721, MAE-0 = 2.3548
Training Round 98: loss = 1.502756, time_cost = 137.0007 sec (0.0840 sec per sample), RMSE-0 = 6.5555, MAPE-0 = 0.3721, MAE-0 = 2.3385
Training Round 99: loss = 1.589883, time_cost = 142.7311 sec (0.0875 sec per sample), RMSE-0 = 6.7490, MAPE-0 = 0.3739, MAE-0 = 2.3697
Training Round 100: loss = 1.544895, time_cost = 137.8782 sec (0.0845 sec per sample), RMSE-0 = 6.7424, MAPE-0 = 0.3733, MAE-0 = 2.3750
!!! Validation : loss = 1.700501, RMSE-0 = 6.5813, MAPE-0 = 0.3815, MAE-0 = 2.3439
Training Round 101: loss = 1.503284, time_cost = 139.7580 sec (0.0857 sec per sample), RMSE-0 = 6.5506, MAPE-0 = 0.3723, MAE-0 = 2.3390
Training Round 102: loss = 1.525604, time_cost = 140.8072 sec (0.0863 sec per sample), RMSE-0 = 6.6517, MAPE-0 = 0.3726, MAE-0 = 2.3436
Training Round 103: loss = 1.542008, time_cost = 140.0630 sec (0.0859 sec per sample), RMSE-0 = 6.6859, MAPE-0 = 0.3734, MAE-0 = 2.3598
Training Round 104: loss = 1.546503, time_cost = 137.2399 sec (0.0841 sec per sample), RMSE-0 = 6.7068, MAPE-0 = 0.3732, MAE-0 = 2.3554
Training Round 105: loss = 1.509061, time_cost = 139.7477 sec (0.0857 sec per sample), RMSE-0 = 6.5714, MAPE-0 = 0.3716, MAE-0 = 2.3320
!!! Validation : loss = 1.604124, RMSE-0 = 5.9433, MAPE-0 = 0.3747, MAE-0 = 2.2554
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 106: loss = 1.551079, time_cost = 139.8388 sec (0.0857 sec per sample), RMSE-0 = 6.7013, MAPE-0 = 0.3729, MAE-0 = 2.3647
Training Round 107: loss = 1.582376, time_cost = 139.2025 sec (0.0853 sec per sample), RMSE-0 = 6.9897, MAPE-0 = 0.3750, MAE-0 = 2.4135
Training Round 108: loss = 1.520038, time_cost = 139.9224 sec (0.0858 sec per sample), RMSE-0 = 6.5445, MAPE-0 = 0.3707, MAE-0 = 2.3256
Training Round 109: loss = 1.556776, time_cost = 144.4418 sec (0.0886 sec per sample), RMSE-0 = 6.9054, MAPE-0 = 0.3729, MAE-0 = 2.3795
Training Round 110: loss = 1.504274, time_cost = 138.6398 sec (0.0850 sec per sample), RMSE-0 = 6.5544, MAPE-0 = 0.3716, MAE-0 = 2.3309
!!! Validation : loss = 1.542307, RMSE-0 = 6.3422, MAPE-0 = 0.3756, MAE-0 = 2.3273
Model: model_save/20220401_00_00_22.pth has been saved since it achieves smaller loss.
Training Round 111: loss = 1.484457, time_cost = 137.3388 sec (0.0842 sec per sample), RMSE-0 = 6.4825, MAPE-0 = 0.3707, MAE-0 = 2.3250
Training Round 112: loss = 1.572456, time_cost = 142.3737 sec (0.0873 sec per sample), RMSE-0 = 6.7676, MAPE-0 = 0.3730, MAE-0 = 2.3852
Training Round 113: loss = 1.593798, time_cost = 139.0067 sec (0.0852 sec per sample), RMSE-0 = 6.9579, MAPE-0 = 0.3750, MAE-0 = 2.4200
Training Round 114: loss = 1.547244, time_cost = 138.4512 sec (0.0849 sec per sample), RMSE-0 = 6.7703, MAPE-0 = 0.3730, MAE-0 = 2.3775
Training Round 115: loss = 1.495386, time_cost = 137.6030 sec (0.0844 sec per sample), RMSE-0 = 6.5855, MAPE-0 = 0.3715, MAE-0 = 2.3369
!!! Validation : loss = 1.981011, RMSE-0 = 6.3417, MAPE-0 = 0.3753, MAE-0 = 2.3180
Training Round 116: loss = 1.529316, time_cost = 138.1262 sec (0.0847 sec per sample), RMSE-0 = 6.7316, MAPE-0 = 0.3739, MAE-0 = 2.3755
Training Round 117: loss = 1.499899, time_cost = 140.9688 sec (0.0864 sec per sample), RMSE-0 = 6.6285, MAPE-0 = 0.3717, MAE-0 = 2.3427
Training Round 118: loss = 1.544241, time_cost = 150.1647 sec (0.0921 sec per sample), RMSE-0 = 6.9167, MAPE-0 = 0.3737, MAE-0 = 2.4071
Training Round 119: loss = 1.499939, time_cost = 154.6105 sec (0.0948 sec per sample), RMSE-0 = 6.5572, MAPE-0 = 0.3705, MAE-0 = 2.3280
Training Round 120: loss = 1.523733, time_cost = 145.4669 sec (0.0892 sec per sample), RMSE-0 = 6.5263, MAPE-0 = 0.3717, MAE-0 = 2.3413
!!! Validation : loss = 1.806201, RMSE-0 = 7.0254, MAPE-0 = 0.3800, MAE-0 = 2.4406
Training Round 121: loss = 1.512889, time_cost = 139.9166 sec (0.0858 sec per sample), RMSE-0 = 6.5626, MAPE-0 = 0.3719, MAE-0 = 2.3406
Training Round 122: loss = 1.519340, time_cost = 139.0042 sec (0.0852 sec per sample), RMSE-0 = 6.5983, MAPE-0 = 0.3716, MAE-0 = 2.3465
Training Round 123: loss = 1.540177, time_cost = 136.0749 sec (0.0834 sec per sample), RMSE-0 = 6.8152, MAPE-0 = 0.3731, MAE-0 = 2.3730
Training Round 124: loss = 1.603532, time_cost = 140.1565 sec (0.0859 sec per sample), RMSE-0 = 6.9189, MAPE-0 = 0.3743, MAE-0 = 2.4023
Training Round 125: loss = 1.501265, time_cost = 140.0810 sec (0.0859 sec per sample), RMSE-0 = 6.6939, MAPE-0 = 0.3716, MAE-0 = 2.3567
!!! Validation : loss = 2.023627, RMSE-0 = 7.0887, MAPE-0 = 0.4002, MAE-0 = 2.5008
Training Round 126: loss = 1.561213, time_cost = 138.7968 sec (0.0851 sec per sample), RMSE-0 = 6.8914, MAPE-0 = 0.3759, MAE-0 = 2.4098
Training Round 127: loss = 1.477208, time_cost = 140.3008 sec (0.0860 sec per sample), RMSE-0 = 6.5424, MAPE-0 = 0.3709, MAE-0 = 2.3274
Training Round 128: loss = 1.540895, time_cost = 140.2021 sec (0.0860 sec per sample), RMSE-0 = 6.8816, MAPE-0 = 0.3720, MAE-0 = 2.3843
Training Round 129: loss = 1.529001, time_cost = 148.5697 sec (0.0911 sec per sample), RMSE-0 = 6.7447, MAPE-0 = 0.3726, MAE-0 = 2.3649
Training Round 130: loss = 1.505918, time_cost = 137.7018 sec (0.0844 sec per sample), RMSE-0 = 6.5591, MAPE-0 = 0.3714, MAE-0 = 2.3452
!!! Validation : loss = 1.664490, RMSE-0 = 6.3299, MAPE-0 = 0.3768, MAE-0 = 2.3073
Training Round 131: loss = 1.532726, time_cost = 142.7943 sec (0.0876 sec per sample), RMSE-0 = 6.5601, MAPE-0 = 0.3719, MAE-0 = 2.3400
Training Round 132: loss = 1.526736, time_cost = 147.3541 sec (0.0903 sec per sample), RMSE-0 = 6.5298, MAPE-0 = 0.3719, MAE-0 = 2.3421
Training Round 133: loss = 1.486874, time_cost = 150.2071 sec (0.0921 sec per sample), RMSE-0 = 6.5307, MAPE-0 = 0.3713, MAE-0 = 2.3255
Training Round 134: loss = 1.555320, time_cost = 148.1317 sec (0.0908 sec per sample), RMSE-0 = 6.6545, MAPE-0 = 0.3726, MAE-0 = 2.3525
Training Round 135: loss = 1.476508, time_cost = 151.1546 sec (0.0927 sec per sample), RMSE-0 = 6.4592, MAPE-0 = 0.3705, MAE-0 = 2.3187
!!! Validation : loss = 1.930809, RMSE-0 = 6.8117, MAPE-0 = 0.3752, MAE-0 = 2.4208
Training Round 136: loss = 1.555064, time_cost = 150.2149 sec (0.0921 sec per sample), RMSE-0 = 6.7822, MAPE-0 = 0.3722, MAE-0 = 2.3658
Training Round 137: loss = 1.558837, time_cost = 149.5921 sec (0.0917 sec per sample), RMSE-0 = 6.8259, MAPE-0 = 0.3721, MAE-0 = 2.3692
Training Round 138: loss = 1.524853, time_cost = 150.9339 sec (0.0925 sec per sample), RMSE-0 = 6.5641, MAPE-0 = 0.3720, MAE-0 = 2.3395
Training Round 139: loss = 1.505981, time_cost = 137.9206 sec (0.0846 sec per sample), RMSE-0 = 6.6736, MAPE-0 = 0.3719, MAE-0 = 2.3427
Training Round 140: loss = 1.541727, time_cost = 137.7694 sec (0.0845 sec per sample), RMSE-0 = 6.6746, MAPE-0 = 0.3715, MAE-0 = 2.3453
!!! Validation : loss = 1.823550, RMSE-0 = 6.8956, MAPE-0 = 0.3838, MAE-0 = 2.3529
Training Round 141: loss = 1.564461, time_cost = 137.9860 sec (0.0846 sec per sample), RMSE-0 = 6.7527, MAPE-0 = 0.3721, MAE-0 = 2.3629
Training Round 142: loss = 1.543073, time_cost = 137.2744 sec (0.0842 sec per sample), RMSE-0 = 6.6610, MAPE-0 = 0.3724, MAE-0 = 2.3511
Training Round 143: loss = 1.525693, time_cost = 137.6841 sec (0.0844 sec per sample), RMSE-0 = 6.6023, MAPE-0 = 0.3719, MAE-0 = 2.3456
Training Round 144: loss = 1.522075, time_cost = 142.5824 sec (0.0874 sec per sample), RMSE-0 = 6.6244, MAPE-0 = 0.3715, MAE-0 = 2.3376
Training Round 145: loss = 1.515319, time_cost = 138.5152 sec (0.0849 sec per sample), RMSE-0 = 6.5497, MAPE-0 = 0.3708, MAE-0 = 2.3330
!!! Validation : loss = 1.981122, RMSE-0 = 6.9340, MAPE-0 = 0.3804, MAE-0 = 2.4102
Training Round 146: loss = 1.508171, time_cost = 139.1109 sec (0.0853 sec per sample), RMSE-0 = 6.5907, MAPE-0 = 0.3722, MAE-0 = 2.3384
Training Round 147: loss = 1.486906, time_cost = 138.3731 sec (0.0848 sec per sample), RMSE-0 = 6.4662, MAPE-0 = 0.3707, MAE-0 = 2.3164
Training Round 148: loss = 1.530891, time_cost = 152.7113 sec (0.0936 sec per sample), RMSE-0 = 6.6307, MAPE-0 = 0.3725, MAE-0 = 2.3503
Training Round 149: loss = 1.508073, time_cost = 150.5632 sec (0.0923 sec per sample), RMSE-0 = 6.5671, MAPE-0 = 0.3716, MAE-0 = 2.3348
Training Round 150: loss = 1.527105, time_cost = 144.1467 sec (0.0884 sec per sample), RMSE-0 = 6.6552, MAPE-0 = 0.3718, MAE-0 = 2.3430
!!! Validation : loss = 1.908124, RMSE-0 = 6.4314, MAPE-0 = 0.3726, MAE-0 = 2.3205
Training Round 151: loss = 1.559630, time_cost = 141.7652 sec (0.0869 sec per sample), RMSE-0 = 6.7668, MAPE-0 = 0.3727, MAE-0 = 2.3698
Training Round 152: loss = 1.529343, time_cost = 141.1854 sec (0.0866 sec per sample), RMSE-0 = 6.4818, MAPE-0 = 0.3712, MAE-0 = 2.3232
Training Round 153: loss = 1.540934, time_cost = 142.2244 sec (0.0872 sec per sample), RMSE-0 = 6.7476, MAPE-0 = 0.3735, MAE-0 = 2.3744
Training Round 154: loss = 1.512204, time_cost = 146.1429 sec (0.0896 sec per sample), RMSE-0 = 6.6384, MAPE-0 = 0.3723, MAE-0 = 2.3419
Training Round 155: loss = 1.505987, time_cost = 144.8493 sec (0.0888 sec per sample), RMSE-0 = 6.6400, MAPE-0 = 0.3716, MAE-0 = 2.3410
!!! Validation : loss = 1.638795, RMSE-0 = 6.7747, MAPE-0 = 0.3798, MAE-0 = 2.3562
Training Round 156: loss = 1.478393, time_cost = 150.7106 sec (0.0924 sec per sample), RMSE-0 = 6.5146, MAPE-0 = 0.3722, MAE-0 = 2.3332
Training Round 157: loss = 1.543478, time_cost = 142.6875 sec (0.0875 sec per sample), RMSE-0 = 6.6650, MAPE-0 = 0.3720, MAE-0 = 2.3439
Training Round 158: loss = 1.567627, time_cost = 139.0987 sec (0.0853 sec per sample), RMSE-0 = 6.8139, MAPE-0 = 0.3730, MAE-0 = 2.3800
Training Round 159: loss = 1.562747, time_cost = 145.4635 sec (0.0892 sec per sample), RMSE-0 = 6.7458, MAPE-0 = 0.3726, MAE-0 = 2.3619
Training Round 160: loss = 1.484489, time_cost = 139.6986 sec (0.0857 sec per sample), RMSE-0 = 6.5476, MAPE-0 = 0.3712, MAE-0 = 2.3281
!!! Validation : loss = 1.970900, RMSE-0 = 7.5359, MAPE-0 = 0.3758, MAE-0 = 2.5248
Training Round 161: loss = 1.502321, time_cost = 141.3258 sec (0.0866 sec per sample), RMSE-0 = 6.5529, MAPE-0 = 0.3709, MAE-0 = 2.3288
Training Round 162: loss = 1.487495, time_cost = 138.0988 sec (0.0847 sec per sample), RMSE-0 = 6.6053, MAPE-0 = 0.3708, MAE-0 = 2.3279
Training Round 163: loss = 1.506261, time_cost = 137.9766 sec (0.0846 sec per sample), RMSE-0 = 6.6306, MAPE-0 = 0.3716, MAE-0 = 2.3428
Training Round 164: loss = 1.486022, time_cost = 140.2930 sec (0.0860 sec per sample), RMSE-0 = 6.5595, MAPE-0 = 0.3705, MAE-0 = 2.3241
Training Round 165: loss = 1.539291, time_cost = 138.7408 sec (0.0851 sec per sample), RMSE-0 = 6.7759, MAPE-0 = 0.3733, MAE-0 = 2.3743
!!! Validation : loss = 1.672483, RMSE-0 = 6.2597, MAPE-0 = 0.3766, MAE-0 = 2.3070
Training Round 166: loss = 1.487136, time_cost = 140.1523 sec (0.0859 sec per sample), RMSE-0 = 6.5250, MAPE-0 = 0.3712, MAE-0 = 2.3321
Training Round 167: loss = 1.532854, time_cost = 137.3897 sec (0.0842 sec per sample), RMSE-0 = 6.6876, MAPE-0 = 0.3729, MAE-0 = 2.3529
Training Round 168: loss = 1.500202, time_cost = 136.1723 sec (0.0835 sec per sample), RMSE-0 = 6.6479, MAPE-0 = 0.3713, MAE-0 = 2.3441
Training Round 169: loss = 1.528166, time_cost = 140.5489 sec (0.0862 sec per sample), RMSE-0 = 6.8175, MAPE-0 = 0.3725, MAE-0 = 2.3648
Training Round 170: loss = 1.507020, time_cost = 137.2340 sec (0.0841 sec per sample), RMSE-0 = 6.5894, MAPE-0 = 0.3711, MAE-0 = 2.3288
!!! Validation : loss = 1.787331, RMSE-0 = 6.6432, MAPE-0 = 0.3736, MAE-0 = 2.3498
Training Round 171: loss = 1.485573, time_cost = 139.0792 sec (0.0853 sec per sample), RMSE-0 = 6.4311, MAPE-0 = 0.3711, MAE-0 = 2.3107
Training Round 172: loss = 1.527708, time_cost = 138.6945 sec (0.0850 sec per sample), RMSE-0 = 6.6686, MAPE-0 = 0.3716, MAE-0 = 2.3545
Training Round 173: loss = 1.545263, time_cost = 137.8458 sec (0.0845 sec per sample), RMSE-0 = 6.7879, MAPE-0 = 0.3726, MAE-0 = 2.3704
Training Round 174: loss = 1.522138, time_cost = 151.0611 sec (0.0926 sec per sample), RMSE-0 = 6.5817, MAPE-0 = 0.3715, MAE-0 = 2.3325
Training Round 175: loss = 1.547419, time_cost = 147.8047 sec (0.0906 sec per sample), RMSE-0 = 6.5997, MAPE-0 = 0.3717, MAE-0 = 2.3428
!!! Validation : loss = 1.711569, RMSE-0 = 6.3378, MAPE-0 = 0.3789, MAE-0 = 2.3145
Training Round 176: loss = 1.501488, time_cost = 140.8713 sec (0.0864 sec per sample), RMSE-0 = 6.5229, MAPE-0 = 0.3711, MAE-0 = 2.3335
Training Round 177: loss = 1.499293, time_cost = 142.1925 sec (0.0872 sec per sample), RMSE-0 = 6.5707, MAPE-0 = 0.3706, MAE-0 = 2.3258
Training Round 178: loss = 1.474874, time_cost = 142.4296 sec (0.0873 sec per sample), RMSE-0 = 6.4753, MAPE-0 = 0.3709, MAE-0 = 2.3154
Training Round 179: loss = 1.506112, time_cost = 141.7279 sec (0.0869 sec per sample), RMSE-0 = 6.5776, MAPE-0 = 0.3712, MAE-0 = 2.3365
Training Round 180: loss = 1.460446, time_cost = 138.5126 sec (0.0849 sec per sample), RMSE-0 = 6.5006, MAPE-0 = 0.3712, MAE-0 = 2.3218
!!! Validation : loss = 1.649597, RMSE-0 = 6.5289, MAPE-0 = 0.3768, MAE-0 = 2.3384
Training Round 181: loss = 1.481747, time_cost = 148.2396 sec (0.0909 sec per sample), RMSE-0 = 6.7341, MAPE-0 = 0.3716, MAE-0 = 2.3467
Training Round 182: loss = 1.508285, time_cost = 150.3126 sec (0.0922 sec per sample), RMSE-0 = 6.6744, MAPE-0 = 0.3726, MAE-0 = 2.3503
Training Round 183: loss = 1.496266, time_cost = 149.6690 sec (0.0918 sec per sample), RMSE-0 = 6.4711, MAPE-0 = 0.3710, MAE-0 = 2.3206
Training Round 184: loss = 1.503239, time_cost = 144.1236 sec (0.0884 sec per sample), RMSE-0 = 6.5149, MAPE-0 = 0.3708, MAE-0 = 2.3273
Training Round 185: loss = 1.496763, time_cost = 142.6084 sec (0.0874 sec per sample), RMSE-0 = 6.5854, MAPE-0 = 0.3716, MAE-0 = 2.3427
!!! Validation : loss = 1.906113, RMSE-0 = 6.4646, MAPE-0 = 0.3821, MAE-0 = 2.3671
Training Round 186: loss = 1.487190, time_cost = 138.4631 sec (0.0849 sec per sample), RMSE-0 = 6.4938, MAPE-0 = 0.3718, MAE-0 = 2.3190
Training Round 187: loss = 1.469256, time_cost = 146.6106 sec (0.0899 sec per sample), RMSE-0 = 6.5037, MAPE-0 = 0.3713, MAE-0 = 2.3163
Training Round 188: loss = 1.504384, time_cost = 137.2086 sec (0.0841 sec per sample), RMSE-0 = 6.5628, MAPE-0 = 0.3710, MAE-0 = 2.3250
Training Round 189: loss = 1.520215, time_cost = 140.7230 sec (0.0863 sec per sample), RMSE-0 = 6.5210, MAPE-0 = 0.3715, MAE-0 = 2.3306
Training Round 190: loss = 1.520166, time_cost = 140.7722 sec (0.0863 sec per sample), RMSE-0 = 6.6354, MAPE-0 = 0.3730, MAE-0 = 2.3504
!!! Validation : loss = 1.875179, RMSE-0 = 6.8413, MAPE-0 = 0.3754, MAE-0 = 2.3743
Training Round 191: loss = 1.499401, time_cost = 140.7918 sec (0.0863 sec per sample), RMSE-0 = 6.5831, MAPE-0 = 0.3718, MAE-0 = 2.3343
Training Round 192: loss = 1.520569, time_cost = 139.0175 sec (0.0852 sec per sample), RMSE-0 = 6.6614, MAPE-0 = 0.3719, MAE-0 = 2.3428
Training Round 193: loss = 1.510373, time_cost = 137.6694 sec (0.0844 sec per sample), RMSE-0 = 6.5574, MAPE-0 = 0.3718, MAE-0 = 2.3371
Training Round 194: loss = 1.503538, time_cost = 139.3447 sec (0.0854 sec per sample), RMSE-0 = 6.6487, MAPE-0 = 0.3718, MAE-0 = 2.3402
Training Round 195: loss = 1.500054, time_cost = 140.2120 sec (0.0860 sec per sample), RMSE-0 = 6.5752, MAPE-0 = 0.3718, MAE-0 = 2.3332
!!! Validation : loss = 1.786750, RMSE-0 = 6.8730, MAPE-0 = 0.3741, MAE-0 = 2.3809
Training Round 196: loss = 1.512603, time_cost = 140.7910 sec (0.0863 sec per sample), RMSE-0 = 6.5549, MAPE-0 = 0.3727, MAE-0 = 2.3348
Training Round 197: loss = 1.472438, time_cost = 140.9200 sec (0.0864 sec per sample), RMSE-0 = 6.6340, MAPE-0 = 0.3716, MAE-0 = 2.3406
Training Round 198: loss = 1.547361, time_cost = 140.3133 sec (0.0860 sec per sample), RMSE-0 = 6.6506, MAPE-0 = 0.3719, MAE-0 = 2.3525
Training Round 199: loss = 1.524497, time_cost = 140.2128 sec (0.0860 sec per sample), RMSE-0 = 6.7375, MAPE-0 = 0.3726, MAE-0 = 2.3578
Training Round 200: loss = 1.567639, time_cost = 146.9930 sec (0.0901 sec per sample), RMSE-0 = 6.8859, MAPE-0 = 0.3743, MAE-0 = 2.3960
!!! Validation : loss = 1.660861, RMSE-0 = 6.2755, MAPE-0 = 0.3722, MAE-0 = 2.3180
> Training finished.

> device: cuda:0
> Loading model_save/20220401_00_00_22.pth
> Model Structure:
GallatExtFull(
  (spatAttLayer): SpatAttLayer(
    (dimSpatAttLayers): ModuleList(
      (0): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (1): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
      (2): MultiHeadPwGaANLayer(
        (pwGaAN): PwGaANLayer(
          (Wa): Linear(in_features=43, out_features=16, bias=False)
          (att_out_fc_l): Linear(in_features=16, out_features=1, bias=False)
          (att_out_fc_r): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_l): Linear(in_features=43, out_features=1, bias=False)
          (gate_fc_m): Linear(in_features=16, out_features=1, bias=False)
          (gate_fc_r): Linear(in_features=43, out_features=1, bias=False)
          (Wg): Linear(in_features=43, out_features=16, bias=False)
        )
      )
    )
    (proj_fc): Linear(in_features=43, out_features=16, bias=False)
    (bn): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tempLayer): TempRecurrentLayer(
    (recurrentBlocks): ModuleList(
      (0): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
      (1): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
      (2): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
      (3): RecurrentBlock(
        (blk_module): LSTM(160, 160)
      )
    )
    (bn): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (tranAttLayer): TranAttLayer(
    (demand_fc): Linear(in_features=640, out_features=1, bias=True)
    (Wa): Linear(in_features=640, out_features=640, bias=False)
    (att_out_fc_l): Linear(in_features=640, out_features=1, bias=False)
    (att_out_fc_r): Linear(in_features=640, out_features=1, bias=False)
  )
)
> Model sent to cuda:0
> Loading DataSet from data/dc2017_0101to0331/
> Total Hours: 2136, starting from 1
> Unify FB Graphs: False, Mix FB Graphs: False
> Validation batches: 6, Test batches: 11
tune = True, ref_extent = -1.00
> Metrics Evaluations for Validation Set:
Demand:
RMSE-0 = 26.2407, RMSE-3 = 35.0976, RMSE-5 = 38.3210
MAPE-0 = 0.4087, MAPE-3 = 0.3269, MAPE-5 = 0.2975
MAE-0 = 8.7537, MAE-3 = 14.7534, MAE-5 = 17.1237
OD:
RMSE-0 = 6.4017, RMSE-3 = 12.3989, RMSE-5 = 14.7201
MAPE-0 = 0.3761, MAPE-3 = 0.3468, MAPE-5 = 0.3282
MAE-0 = 2.3422, MAE-3 = 6.3681, MAE-5 = 8.2147
> Metrics Evaluations for Test Set:
Demand:
RMSE-0 = 31.1292, RMSE-3 = 41.5271, RMSE-5 = 45.2537
MAPE-0 = 0.3375, MAPE-3 = 0.2702, MAPE-5 = 0.2446
MAE-0 = 9.8697, MAE-3 = 16.7271, MAE-5 = 19.4647
OD:
RMSE-0 = 8.1518, RMSE-3 = 15.6482, RMSE-5 = 18.5462
MAPE-0 = 0.3669, MAPE-3 = 0.3282, MAPE-5 = 0.3064
MAE-0 = 2.5826, MAE-3 = 7.1179, MAE-5 = 9.2201
> Evaluation finished.
